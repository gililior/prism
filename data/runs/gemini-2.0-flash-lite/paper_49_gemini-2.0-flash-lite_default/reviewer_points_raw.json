[
  {
    "kind": "strength",
    "text": "The paper leverages existing datasets and translation services to create a multilingual summarization dataset, which is clearly described.",
    "grounding": "Sec 3.1",
    "facet": "methods"
  },
  {
    "kind": "weakness",
    "text": "The human evaluation section lacks detailed scoring guidelines and relies on subjective judgments, potentially affecting the reliability of the results.",
    "grounding": "Sec C",
    "facet": "methods"
  },
  {
    "kind": "suggestion",
    "text": "Provide a more detailed breakdown of the human evaluation scores, including inter-annotator agreement metrics.",
    "grounding": "Sec C",
    "facet": "methods"
  },
  {
    "kind": "suggestion",
    "text": "Include a section on limitations of the study, such as the potential biases introduced by the machine translation process.",
    "grounding": "Sec 3.1",
    "facet": "methods"
  },
  {
    "kind": "suggestion",
    "text": "Compare the performance of the proposed method with strong baselines on a wider range of language pairs.",
    "grounding": "Table 2",
    "facet": "methods"
  },
  {
    "kind": "strength",
    "text": "The paper details the datasets used, including their sources and how they were processed.",
    "grounding": "Section 3.1",
    "facet": "code/data availability"
  },
  {
    "kind": "weakness",
    "text": "The paper does not mention the use of seeds or report variance.",
    "grounding": "Section 3.1, Appendix B",
    "facet": "seeds/variance"
  },
  {
    "kind": "weakness",
    "text": "The paper does not provide information about the computational environment used for training and evaluation.",
    "grounding": "Section 3.1, Appendix B",
    "facet": "environment reproducibility"
  },
  {
    "kind": "suggestion",
    "text": "Provide a link to the code repository, including training and evaluation scripts.",
    "grounding": "GitHub link placeholder",
    "facet": "code/data availability"
  },
  {
    "kind": "suggestion",
    "text": "Specify and report the seeds used for all experiments. Report variance (e.g., standard deviation) across multiple runs.",
    "grounding": "Section 3.1, Appendix B",
    "facet": "seeds/variance"
  },
  {
    "kind": "suggestion",
    "text": "Provide details about the hardware and software environment (e.g., operating system, Python version, library versions, CUDA version) used for the experiments. Consider using a Dockerfile or a similar tool to ensure environment reproducibility.",
    "grounding": "Section 3.1, Appendix B",
    "facet": "environment reproducibility"
  },
  {
    "kind": "question",
    "text": "Are the datasets used publicly available, or can they be made available?",
    "grounding": "Section 3.1",
    "facet": "code/data availability"
  },
  {
    "kind": "question",
    "text": "Were multiple runs performed for each experiment? If so, what was the variance?",
    "grounding": "Section 3.1, Appendix B",
    "facet": "seeds/variance"
  },
  {
    "kind": "question",
    "text": "Can the authors provide the exact configuration of the mBART-50 model used?",
    "grounding": "Section 3.1, Appendix B",
    "facet": "environment reproducibility"
  },
  {
    "kind": "limitation",
    "text": "The paper lacks information on the computational resources used for training and evaluation.",
    "grounding": "Section 3.1, Appendix B",
    "facet": "environment reproducibility"
  },
  {
    "kind": "ethics_flag",
    "text": "No",
    "grounding": "Section 3.1, Appendix B",
    "facet": "ethics"
  },
  {
    "kind": "strength",
    "text": "The paper addresses the important and often overlooked issue of translationese in cross-lingual summarization, a relevant problem given the reliance on translated data in this field.",
    "grounding": "Intro",
    "facet": "originality"
  },
  {
    "kind": "strength",
    "text": "The paper systematically investigates the impact of translationese on CLS model evaluation and performance, considering both source documents and target summaries.",
    "grounding": "Intro, Sec 3, Sec 4",
    "facet": "originality"
  },
  {
    "kind": "weakness",
    "text": "The paper lacks specific details on the CLS models used for evaluation, making it difficult to assess the generalizability of the findings. It is unclear what constitutes 'real-world applications' in the context of the study.",
    "grounding": "Sec 3, Sec 4",
    "facet": "positioning"
  },
  {
    "kind": "suggestion",
    "text": "Include a detailed comparison of the proposed approach with existing CLS methods, quantifying the performance differences and highlighting the advantages of addressing translationese.",
    "grounding": "Sec 3, Sec 4",
    "facet": "comparative evidence"
  },
  {
    "kind": "suggestion",
    "text": "Provide more details on the datasets used, including their sources, translation methods, and characteristics. This will help in understanding the scope and limitations of the study.",
    "grounding": "Sec 2.1",
    "facet": "comparative evidence"
  },
  {
    "kind": "question",
    "text": "How does the degree of translationese correlate with the performance degradation observed in the experiments?",
    "grounding": null,
    "facet": "originality"
  },
  {
    "kind": "question",
    "text": "What specific metrics are used to quantify translationese, and how are they chosen?",
    "grounding": null,
    "facet": "originality"
  },
  {
    "kind": "limitations",
    "text": "The novelty hinges on the specific datasets and CLS models used, and the generalizability of the findings may be limited by these choices.",
    "grounding": null,
    "facet": "originality"
  },
  {
    "kind": "ethics_flag",
    "text": "no",
    "grounding": null,
    "facet": "ethics"
  },
  {
    "kind": "summary",
    "text": "The paper investigates the impact of translationese on cross-lingual summarization (CLS) models and proposes suggestions for dataset and model development.",
    "grounding": null,
    "facet": "summary"
  },
  {
    "kind": "strength",
    "text": "The paper provides concrete suggestions for future dataset and model developments based on the findings of the investigation. (Sec 5)",
    "grounding": "Sec 5",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "strength",
    "text": "The paper discusses the importance of controlling translationese in test sets and suggests strategies to mitigate its effects. (Sec 5)",
    "grounding": "Sec 5",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "weakness",
    "text": "The paper does not provide specific experimental results or quantitative analysis to support all the suggestions made for future work.",
    "grounding": "Insufficient evidence",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "weakness",
    "text": "The paper overclaims the generalizability of its findings without sufficient evidence across diverse languages and datasets.",
    "grounding": "Insufficient evidence",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "suggestion",
    "text": "Conduct experiments on a wider range of languages and datasets to validate the generalizability of the findings and suggestions.",
    "grounding": "Insufficient evidence",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "suggestion",
    "text": "Provide quantitative analysis to support the effectiveness of the proposed strategies for controlling translationese in test sets and designing translationese-aware CLS models.",
    "grounding": "Sec 5",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "questions",
    "text": "What specific post-processing strategies are recommended to reduce translationese in machine-translated documents or summaries?",
    "grounding": null,
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "questions",
    "text": "How does the proposed 'tagged training strategy' explicitly model different degrees of translationese?",
    "grounding": null,
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "questions",
    "text": "What are the specific metrics used to evaluate the performance of the CLS models, and how do they account for translationese?",
    "grounding": null,
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "limitations",
    "text": "The authors acknowledge the limitations of the human evaluation method and the challenges in constructing a perfect quantitative human evaluation principle. (Sec C)",
    "grounding": "Sec C",
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "ethics_flag",
    "text": "no",
    "grounding": null,
    "facet": "claims_vs_evidence"
  },
  {
    "kind": "summary",
    "text": "The paper's figures present human evaluation results for summarization models. The figures appear to show performance comparisons across different language pairs and models.",
    "grounding": "Figures 1-10",
    "facet": "figures"
  },
  {
    "kind": "strength",
    "text": "The figures effectively present the human evaluation setup and the different language pairs and models being compared.",
    "grounding": "Figures showing the different language pairs and models.",
    "facet": "figures"
  },
  {
    "kind": "weakness",
    "text": "The figures lack specific details about the evaluation metrics used (Informativeness, Fluency, Overall).",
    "grounding": "All figures",
    "facet": "figures"
  },
  {
    "kind": "suggestion",
    "text": "Include a clear legend to explain the different models and language pairs represented in each figure. Add axis labels with units.",
    "grounding": "All figures",
    "facet": "figures"
  },
  {
    "kind": "questions",
    "text": "Are the scores normalized or raw scores? What are the specific evaluation metrics used?",
    "grounding": "All figures",
    "facet": "figures"
  },
  {
    "kind": "limitations",
    "text": "The visualizations are limited to showing overall performance scores and do not provide insights into specific types of errors or strengths of the models.",
    "grounding": "All figures",
    "facet": "figures"
  },
  {
    "kind": "ethics_flag",
    "text": "no",
    "grounding": "N/A",
    "facet": "figures"
  },
  {
    "kind": "summary",
    "text": "The tables present experimental results and statistical analyses of summarization models across different datasets and language pairs. The tables vary in completeness, with some lacking crucial statistical information.",
    "grounding": "Tables 1-10",
    "facet": "tables"
  },
  {
    "kind": "strength",
    "text": "Table 6 includes t-test p-values to indicate statistical significance.",
    "grounding": "Table 6",
    "facet": "tables"
  },
  {
    "kind": "weakness",
    "text": "Several tables lack standard deviations, confidence intervals, or p-values, making it difficult to assess the significance of the results. Table 1 lacks clarity in the definition of 'Text Type'.",
    "grounding": "Tables 1, 3, 4, 5, 7, 8, 9, 10",
    "facet": "tables"
  },
  {
    "kind": "suggestion",
    "text": "Include standard deviations or confidence intervals for all reported metrics. Add p-values to indicate statistical significance of performance differences between models in all tables. Clarify the definition of 'Text Type' in Table 1.",
    "grounding": "Tables 1-10",
    "facet": "tables"
  },
  {
    "kind": "questions",
    "text": "What statistical tests were used to determine significance in Table 6? What is the definition of 'Text Type' in Table 1? Are the differences in human evaluation scores statistically significant in Tables 4 and 7? How were the hard and simple test subsets defined in Table 10? What is the scale for each dataset in Table 9?",
    "grounding": "Tables 1, 4, 6, 7, 9, 10",
    "facet": "tables"
  },
  {
    "kind": "limitations",
    "text": "The conclusions are limited by the specific datasets and models evaluated. The human evaluation is limited by the subjective nature of the scoring.",
    "grounding": "All tables",
    "facet": "tables"
  },
  {
    "kind": "ethics_flag",
    "text": "no",
    "grounding": "N/A",
    "facet": "tables"
  },
  {
    "kind": "strength",
    "text": "The abstract clearly outlines the paper's focus, contributions, and findings.",
    "grounding": "Abstract",
    "facet": "organization"
  },
  {
    "kind": "strength",
    "text": "The introduction provides a good overview of the CLS task and its challenges, citing relevant literature.",
    "grounding": "Introduction",
    "facet": "clarity_presentation"
  },
  {
    "kind": "weakness",
    "text": "The definition of 'translationese' could be made more precise, especially in the context of its impact on CLS.",
    "grounding": "Introduction, Sec 2.1",
    "facet": "clarity_presentation"
  },
  {
    "kind": "weakness",
    "text": "The paper lacks a clear notation section, making it difficult to follow the mathematical aspects of the methods.",
    "grounding": "Methods Section (if any)",
    "facet": "clarity_presentation"
  },
  {
    "kind": "suggestion",
    "text": "Provide a more detailed explanation of the metrics used to quantify translationese.",
    "grounding": "Section 3",
    "facet": "clarity_presentation"
  },
  {
    "kind": "suggestion",
    "text": "Include a table summarizing the key findings regarding the impact of translationese on model evaluation and performance.",
    "grounding": "Section 3 & 4",
    "facet": "organization"
  },
  {
    "kind": "suggestion",
    "text": "Define all acronyms at first use.",
    "grounding": "Abstract, Introduction",
    "facet": "clarity_presentation"
  },
  {
    "kind": "questions",
    "text": "How does the degree of translationese correlate with the performance degradation observed in CLS models?",
    "grounding": "Section 3 & 4",
    "facet": "clarity_presentation"
  },
  {
    "kind": "questions",
    "text": "What specific training strategies are beneficial for low-resource languages when using machine-translated documents?",
    "grounding": "Abstract, Section 4",
    "facet": "clarity_presentation"
  },
  {
    "kind": "limitations",
    "text": "The paper's reproducibility depends on the availability of the datasets and the specific CLS models used.",
    "grounding": "Methods Section",
    "facet": "reproducibility"
  },
  {
    "kind": "ethics_flag",
    "text": "No ethical concerns are apparent.",
    "grounding": "N/A",
    "facet": "ethics"
  },
  {
    "kind": "ratings",
    "text": "Overall, the paper is well-structured and addresses an important issue in CLS. However, improving the clarity of definitions and providing more detailed explanations of the methods would strengthen the paper.",
    "grounding": "Overall",
    "facet": "overall"
  },
  {
    "kind": "weakness",
    "text": "No discussion of potential misuse or failure modes.",
    "grounding": "Insufficient evidence",
    "facet": "societal_impact"
  },
  {
    "kind": "suggestion",
    "text": "Add a Broader Impact section with mitigation strategies.",
    "grounding": "Conclusion",
    "facet": "societal_impact"
  },
  {
    "kind": "strength",
    "text": "The paper's focus on the impact of translationese in cross-lingual summarization (CLS) is novel, as it explicitly investigates how translationese affects CLS model evaluation and performance, which is a different focus than prior work such as [2] which focuses on creating a new benchmark dataset for CLS.",
    "grounding": "Intro/Related Work",
    "facet": "novelty"
  },
  {
    "kind": "weakness",
    "text": "The paper should include a more direct comparison with [1], which explores the influence of translationese on machine translation evaluation. While the current paper focuses on CLS, a comparison of the methods used to identify and mitigate translationese, and their effectiveness in the context of summarization, would strengthen the paper.",
    "grounding": "Related Work",
    "facet": "comparison"
  },
  {
    "kind": "suggestion",
    "text": "To strengthen the analysis, the paper could include an experiment where the proposed method is compared against a baseline that uses the techniques described in [1] to mitigate translationese in the training data. This would help to quantify the improvements achieved by the new approach.",
    "grounding": "Sec X",
    "facet": "experiment"
  }
]