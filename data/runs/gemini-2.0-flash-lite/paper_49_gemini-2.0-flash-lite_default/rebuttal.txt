{
  "rebuttal": [
    {
      "reviewer_feedback": "Weaknesses (9 points): The human evaluation section lacks detailed scoring guidelines and relies on subjective judgments, potentially affecting the reliability of the results. (Sec C)",
      "response": "We acknowledge the reviewer's concern regarding the subjectivity of human evaluation. While we agree that subjective judgments are inherent in human evaluation, we believe the paper adequately addresses this. Section C provides a clear description of the metrics used (Informativeness, Fluency, and Overall Quality) and the 3-point scale. We also explicitly state that evaluators were provided with a brief guideline for each metric. We believe the reviewer may have overlooked this. Furthermore, we report Fleiss' Kappa scores in Section 3.3, which indicate a good inter-annotator agreement (0.46, 0.37, and 0.52 for Informativeness, Fluency, and Overall, respectively), mitigating concerns about reliability. We will consider adding more detailed scoring rubrics in the appendix for future versions, but we believe the current level of detail is standard for this type of evaluation, as we also mentioned in Section C."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): The paper does not mention the use of seeds or report variance. (Section 3.1, Appendix B)",
      "response": "We acknowledge this weakness and will address it in the revised version. We will specify the seeds used for all experiments and report the variance (e.g., standard deviation) across multiple runs. This will be included in Section 3.1 and Appendix B, as suggested."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): The paper does not provide information about the computational environment used for training and evaluation. (Section 3.1, Appendix B)",
      "response": "We acknowledge this omission. We will include details about the hardware and software environment used for the experiments in the revised version, specifically in Section 3.1 and Appendix B. We will also consider providing a Dockerfile to ensure environment reproducibility, as suggested."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): The paper lacks specific details on the CLS models used for evaluation, making it difficult to assess the generalizability of the findings. (Sec 3, Sec 4)",
      "response": "We respectfully disagree. The paper explicitly states that we use mBART-50 (Tang et al., 2021) as the CLS model. The implementation details, including the number of parameters, are provided in Appendix B. We believe the reviewer may have overlooked this. We fine-tune the model on NVIDIA Tesla V100 GPUs (32G) and set the learning rate to 5e-6, the warmup steps to 500, the epochs to 10, and the batch size is 4. The maximum number of tokens for input sequences is 1024. In the test process, beam size is set to 5. All experimental results listed in this paper are the average of 3 runs. We believe that mBART-50 is a well-established model in the CLS field, and our findings are generalizable to other transformer-based models. We will consider adding a brief discussion of this in the revised version."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): The paper overclaims the generalizability of its findings without sufficient evidence across diverse languages and datasets. (Insufficient evidence)",
      "response": "We acknowledge the need for more extensive validation. While our experiments cover English, Chinese, Russian, Arabic, and Czech, we agree that expanding the scope would strengthen our conclusions. We will include a statement in the conclusion acknowledging this limitation and suggesting future work to extend our method to more languages and language families. We will also emphasize that our findings are a starting point for understanding the impact of translationese."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): Several tables lack standard deviations, confidence intervals, or p-values, making it difficult to assess the significance of the results. (Tables 1, 3, 4, 5, 7, 8, 9, 10)",
      "response": "We acknowledge this weakness. We will include standard deviations or confidence intervals for all reported metrics in the revised version. We will also add p-values to indicate the statistical significance of performance differences between models in all tables, as suggested."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): The definition of 'translationese' could be made more precise. (Introduction, Sec 2.1)",
      "response": "We agree that a more precise definition would be beneficial. We will refine the definition of 'translationese' in the introduction and Section 2.1, drawing upon the existing literature (Gellerstam, 1986; Baker et al., 1993; Scarpa, 2006; etc.) to provide a more comprehensive overview of its characteristics."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): No discussion of potential misuse or failure modes. (Insufficient evidence)",
      "response": "We acknowledge this omission. We will add an Ethical Considerations section to the paper, as suggested. This section will discuss potential misuse, such as the propagation of biases present in the training data, and the limitations of our approach. We will also include mitigation strategies."
    },
    {
      "reviewer_feedback": "Weaknesses (9 points): The paper should include a more direct comparison with [1], which explores the influence of translationese on machine translation evaluation. (Related Work)",
      "response": "We will add a more direct comparison with [1] (Zhang and Toral, 2019) in the Related Work section. We will highlight the similarities and differences between our work and theirs, specifically focusing on how we address the impact of translationese in the context of CLS, which is a different task than machine translation evaluation."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Provide a more detailed breakdown of the human evaluation scores, including inter-annotator agreement metrics. (Sec C)",
      "response": "We believe we have addressed this in the response to the first weakness. We will consider adding more detailed scoring rubrics in the appendix for future versions, but we believe the current level of detail is standard for this type of evaluation, as we also mentioned in Section C."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Specify and report the seeds used for all experiments and report variance (e.g., standard deviation) across multiple runs. (Section 3.1, Appendix B)",
      "response": "We will address this in the revised version. We will specify the seeds used for all experiments and report the variance (e.g., standard deviation) across multiple runs. This will be included in Section 3.1 and Appendix B, as suggested."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Provide details about the hardware and software environment used for the experiments, and consider using a Dockerfile or a similar tool to ensure environment reproducibility. (Section 3.1, Appendix B)",
      "response": "We will address this in the revised version. We will include details about the hardware and software environment used for the experiments in the revised version, specifically in Section 3.1 and Appendix B. We will also consider providing a Dockerfile to ensure environment reproducibility, as suggested."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Include a detailed comparison of the proposed approach with existing CLS methods, quantifying the performance differences and highlighting the advantages of addressing translationese. (Sec 3, Sec 4)",
      "response": "We believe that our paper already provides a comparison with existing CLS methods. We compare our results with those of mBART-HT and mBART-MT, demonstrating the impact of translationese. We will clarify the performance differences and highlight the advantages of addressing translationese more explicitly in the revised version, particularly in Sections 3 and 4. We will also add a discussion of how our findings can inform the development of future CLS methods."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Conduct experiments on a wider range of languages and datasets to validate the generalizability of the findings and suggestions. (Insufficient evidence)",
      "response": "We acknowledge the need for more extensive validation. While our experiments cover English, Chinese, Russian, Arabic, and Czech, we agree that expanding the scope would strengthen our conclusions. We will include a statement in the conclusion acknowledging this limitation and suggesting future work to extend our method to more languages and language families. We will also emphasize that our findings are a starting point for understanding the impact of translationese."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Include standard deviations or confidence intervals for all reported metrics. Add p-values to indicate statistical significance of performance differences between models in all tables. Clarify the definition of 'Text Type' in Table 1. (Tables 1-10)",
      "response": "We will address this in the revised version. We will include standard deviations or confidence intervals for all reported metrics. We will also add p-values to indicate the statistical significance of performance differences between models in all tables. We will clarify the definition of 'Text Type' in Table 1."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Define all acronyms at first use. (Abstract, Introduction)",
      "response": "We will define all acronyms at their first use in the abstract and introduction."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): Add a Broader Impact section with mitigation strategies. (Conclusion)",
      "response": "We will add an Ethical Considerations section to the paper, as suggested. This section will discuss potential misuse, such as the propagation of biases present in the training data, and the limitations of our approach. We will also include mitigation strategies."
    },
    {
      "reviewer_feedback": "Suggestions (9 points): To strengthen the analysis, the paper could include an experiment where the proposed method is compared against a baseline that uses the techniques described in [1] to mitigate translationese in the training data. (Sec X)",
      "response": "We appreciate the suggestion. However, directly implementing the techniques from [1] (Zhang and Toral, 2019) is not straightforward in our CLS setting, as their focus is on machine translation evaluation, not training. We will, however, strengthen the analysis by including a more detailed discussion of [1] in the Related Work section, highlighting the differences in methodology and scope. We will also discuss how our findings can inform the development of future CLS methods that might incorporate techniques to mitigate translationese."
    }
  ]
}