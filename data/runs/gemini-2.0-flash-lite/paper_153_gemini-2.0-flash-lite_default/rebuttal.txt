[
  {
    "rebuttal": "We sincerely appreciate the reviewer's thorough and insightful feedback. We have carefully considered each point and provide detailed responses below.\n\n**Weaknesses:**\n\n*   **Weakness 1: Lack of detailed comparison with closest baselines.** The reviewer states that the paper lacks a detailed comparison with the closest baseline models. We believe this is addressed in Section 5, where we compare our models (PISTAQ and SREQA) with BERT, BERT-EQ, and GPT3.5. We provide detailed results and discussions on the performance differences between these models across various datasets (SPARTQA-AUTO, SPARTQA-HUMAN, and RESQ) in Tables 5, 6, and 7, respectively. We also analyze the strengths and weaknesses of each model in relation to the others. We respectfully disagree with the reviewer's assessment, as we believe the paper provides a comprehensive comparison with the relevant baselines.\n\n*   **Weakness 2: Lack of detailed axis labels, units, and statistical information in tables.** We acknowledge this point. While we provide accuracy, precision, recall, and F1-score metrics, we did not include standard deviations, confidence intervals, or p-values. We will address this in the next version by including standard deviations where appropriate, especially for the human-generated datasets, to better indicate the variability of the results. We will also consider using bar charts or line graphs to visualize the results.\n\n*   **Weakness 3: Overclaiming generalizability of PISTAQ.** The reviewer is correct that PISTAQ underperforms on RESQ. We acknowledge this limitation in Section 5.2, where we explicitly state that PISTAQ's performance is inferior to other baselines on RESQ (Table 7). We attribute this to the absence of integrating commonsense information in PISTAQ and errors in the extraction modules. We believe the paper accurately reflects the limitations of PISTAQ and does not overclaim its generalizability. We will clarify this further in the conclusion.\n\n*   **Weakness 4: Vague definition of 'implicit spatial relations'.** The definition of 'implicit spatial relations' is provided in the Introduction (ยง1) as \"inferring the implicit 1 spatial relations from explicit relations 2 described in the text.\" We also provide an example in Figure 1. We will enhance this definition by providing more explicit examples of implicit spatial relations (e.g., inferring \"above\" from \"on top of\") in the revised version.\n\n*   **Weakness 5: Lack of a clear notation section.** We acknowledge the lack of a dedicated notation section. We will add a table summarizing the key notations used in the mathematical formulations and model descriptions in the next version.\n\n*   **Weakness 6: Lack of ethical considerations.** We acknowledge the importance of addressing ethical considerations. We will add a new section to the paper discussing potential ethical risks, such as bias and misuse, and outline mitigation strategies. This will include a discussion of data privacy, potential biases in the datasets, and responsible use of the models.\n\n**Suggestions:**\n\n*   **Suggestion 1: Include a direct comparison with a state-of-the-art model that also addresses spatial reasoning.** We believe we have addressed this by comparing our models with BERT, BERT-EQ, and GPT3.5, which are strong baselines in the field. We will clarify in the introduction that these are the most relevant baselines for comparison.\n\n*   **Suggestion 2: Add error bars or confidence intervals to the tables.** We will incorporate this suggestion in the next version, as mentioned in our response to Weakness 2.\n\n*   **Suggestion 3: Conduct experiments to isolate the impact of each component in the PISTAQ pipeline.** While we do not have separate experiments to isolate the impact of each component, we provide an ablation study by comparing PISTAQ with GT-PISTAQ (Section 4.2). GT-PISTAQ uses ground truth values for all modules, which helps to evaluate the reasoning module. We will clarify this in the revised version.\n\n*   **Suggestion 4: Evaluate PISTAQ on datasets with varying degrees of reliance on commonsense knowledge.** We agree that this is a valuable suggestion. We will discuss this in the future work section, highlighting the need to incorporate commonsense knowledge to improve the performance of PISTAQ on real-world datasets like RESQ.\n\n*   **Suggestion 5: Provide a more detailed explanation of the 'rules' used in the symbolic reasoning component.** We will expand on the explanation of the rules used in the symbolic reasoning component and provide more examples of these rules in the revised version. The rules are listed in Table 2.\n\n*   **Suggestion 6: Include a table summarizing the key differences between the proposed models.** We will incorporate this suggestion in the revised version.\n\n*   **Suggestion 7: Add a notation table.** We will incorporate this suggestion in the revised version.\n\n*   **Suggestion 8: Include a section detailing the datasets used, their sources, and any associated licenses or usage restrictions.** We will add a section detailing the datasets used, their sources, and any associated licenses or usage restrictions in the next version.\n\n*   **Suggestion 9: Address potential ethical risks.** We will incorporate this suggestion in the revised version.\n\nWe believe these revisions will significantly improve the clarity and impact of our paper. Thank you again for your valuable feedback."
  }
]