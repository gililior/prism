[
  {
    "rebuttal": "We thank the reviewer for their thorough and insightful feedback. We address each point below:\n\n**Weaknesses:**\n\n*   **Lack of quantitative comparisons with existing methods and unclear novelty:** We respectfully disagree that the paper lacks clarity on novelty. The introduction (Section 1) and related work (Section 8) explicitly discuss the differences between our work and existing methods. We highlight the novel focus on the *internal recall process* of factual associations, contrasting it with prior work that primarily focuses on knowledge *localization* (e.g., Meng et al., 2022a; Wallat et al., 2020). We also emphasize the key role of lower MLP sublayers and MHSA parameters, which is different from prior work. While we do not directly compare with existing methods quantitatively, our work provides a novel mechanistic understanding of the internal processes. We will add a sentence in the abstract and introduction to emphasize the novelty of our approach.\n\n*   **Overclaiming generalizability:** We acknowledge this concern. While we analyze two GPT models, GPT-2 and GPT-J, we agree that further validation on diverse models and tasks is needed. We will add a section in the conclusion to explicitly state this limitation and suggest future work to address it. We will also add a sentence in the introduction to clarify that our findings are based on the analysis of two GPT models.\n\n*   **Missing figure labels:** We apologize for the lack of clarity in some figures. We will revise Figures 3, 4, 5, 6, 13, 14, 15, 16, 17, 18, and 19 to include clear axis labels, units where applicable, and legends. We believe that the figures are understandable, but we will improve them to make them clearer.\n\n*   **Missing statistical significance in tables:** We will add standard deviations or confidence intervals to Tables 1, 3, 4, and 5 to quantify the variability in the results. We will also add p-values to indicate statistical significance where appropriate. We will add clear labels for the columns in Table 5.\n\n*   **Unclear definition of 'enrichment process':** We will provide a more detailed definition of the 'enrichment process' in the introduction. As described in Section 1 and Section 6, the enrichment process refers to the construction of an attribute-rich subject representation at the last subject position, driven by the early MLP sublayers. We will clarify this definition and provide more details on how it is measured or identified.\n\n*   **Lack of ethical considerations:** We acknowledge this important concern. We will add a section on the datasets used, including their licenses, any consent obtained, and privacy considerations. We will also add a Broader Impact section with mitigation strategies in the conclusion.\n\n*   **Lack of discussion on misuse and failure modes:** We will add a section in the conclusion to address potential misuse and failure modes.\n\n*   **Lack of comparison with related work on representation evolution and knowledge packing:** We address this in Section 8 (Related Work). We will expand this section to explicitly compare our findings with related work on representation evolution and knowledge packing.\n\n**Suggestions:**\n\n*   **Comparative analysis with existing methods:** We believe that we already address this in the introduction and related work. We will expand the related work section to highlight the differences in the identified mechanisms.\n\n*   **Quantitative results on the percentage of predictions:** We will add quantitative results on the percentage of predictions where the identified mechanism is observed. As shown in Section 7.1 and Table 2, we already provide the extraction rate for the MHSA and MLP sublayers.\n\n*   **Experiments on different model architectures and datasets:** We acknowledge the need for further validation. We will add a section in the conclusion to suggest future work to address this.\n\n*   **Add clear labels to all axes and legends:** We will revise the figures as suggested.\n\n*   **Include standard deviations and p-values:** We will revise the tables as suggested.\n\n*   **More detailed definition of the 'enrichment process':** We will revise the introduction as suggested.\n\n*   **Include a detailed section on the datasets used:** We will add a section as suggested.\n\n*   **Add a Broader Impact section:** We will add a section as suggested.\n\n*   **Compare the proposed method with the findings in [1], [2], and [3]:** We will expand the related work section to address these suggestions.\n\nWe believe that these revisions will significantly improve the clarity and impact of our paper. Thank you again for your valuable feedback."
  }
]