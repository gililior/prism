[
  {
    "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the time and effort invested in reviewing our paper. We address each point below:\n\n**Weaknesses:**\n\n*   **Weakness 1: Stronger evidence to distinguish results from baselines.** We respectfully disagree. Table 1 directly compares our results with the baseline model (Anwar et al., 2023). We highlight the performance improvements, particularly in low-resource languages like German (DE), with a 7.91 WER reduction (14% relative). We believe this provides sufficient evidence of our model's superior performance. We will clarify this further in the revised manuscript by explicitly stating the relative improvement percentages in the abstract and introduction.\n\n*   **Weakness 2: Lack of seeds for training and evaluation.** The reviewer is correct; we did not explicitly mention the use of seeds. We acknowledge this omission and will include the random seeds used for all experiments in Section 3.2 (Implementation Details) and report the standard deviation of the results across multiple runs in Table 1 to assess the variance of the results.\n\n*   **Weakness 3: Details about the environment used.** We acknowledge this and will add a sentence in Section 3.2 (Implementation Details) specifying the software versions (e.g., PyTorch, CUDA) and hardware configurations (e.g., GPU model) used for training and evaluation.\n\n*   **Weakness 4: Dataset license, consent, or privacy measures.** We acknowledge this is missing. We will add a new paragraph in Section 3.1 (Datasets) to detail the dataset license, consent procedures, and privacy considerations for the MuAViC dataset, as provided by Anwar et al. (2023).\n\n*   **Weakness 5: Figures lack axis labels and units.** The reviewer is correct. We will revise all figures to include clear axis labels and units where applicable. We will also add legends to explain any color-coding or symbols used.\n\n*   **Weakness 6: Table 1 lacks standard deviations, confidence intervals, or p-values.** We acknowledge this and will include standard deviations in Table 1 to quantify the significance of the performance differences. We will consider adding p-values if feasible, given the computational resources.\n\n*   **Weakness 7: Unclear definition of \"linguistic representation extractor\".** We acknowledge this. We will expand Section 2.1 (Linguistic Representation Extractor) to provide a more detailed explanation of its function, architecture, input, and output. We will clarify how the prompts are used to extract language-specific features.\n\n*   **Weakness 8: Lack of a comprehensive notation section.** We acknowledge this and will add a notation table or glossary in Section 2 to define all symbols and variables used in the paper, improving readability.\n\n*   **Weakness 9: Potential biases and model performance across languages/demographics.** We acknowledge this is missing. We will add a discussion in Section 5 (Conclusion) about potential biases in the training data and the model's performance across different languages and demographic groups, acknowledging the limitations of our current evaluation.\n\n*   **Weakness 10: Potential for misuse of the technology.** We acknowledge this is missing. We will add a brief discussion in Section 5 (Conclusion) about potential misuse cases and mitigation strategies, emphasizing responsible AI development.\n\n*   **Weakness 11: Lack of a dedicated section on broader societal impacts.** We acknowledge this is missing. We will add a brief discussion in Section 5 (Conclusion) about the potential societal impacts, including job displacement or creation, and the ethical considerations of our work.\n\n**Suggestions:**\n\n*   **Suggestion 1: Head-to-head comparison with a contemporaneous method.** We will add a head-to-head comparison with a contemporaneous method if possible. However, the field is rapidly evolving, and finding a directly comparable, publicly available model trained on the same dataset is challenging. We will investigate this further.\n\n*   **Suggestion 2: Include random seeds and report variance.** As stated above, we will include the random seeds and report the standard deviation of the results in Table 1.\n\n*   **Suggestion 3: Provide a link to the code repository.** We are unable to provide a link to the code repository at this time due to institutional policy. However, we will include a requirements file (e.g., `environment.yml` or `requirements.txt`) to specify the software dependencies.\n\n*   **Suggestion 4: Include a section detailing the dataset license, consent procedures, and privacy considerations.** We will add a new paragraph in Section 3.1 (Datasets) to address this.\n\n*   **Suggestion 5: Add clear labels to all axes, including units where applicable.** We will revise all figures to include clear axis labels and units where applicable.\n\n*   **Suggestion 6: Include standard deviations and p-values to quantify the significance of the performance differences in Table 1.** We will include standard deviations in Table 1.\n\n*   **Suggestion 7: Provide a detailed explanation of the \"linguistic representation extractor\".** We will expand Section 2.1 (Linguistic Representation Extractor) to provide a more detailed explanation.\n\n*   **Suggestion 8: Include a notation table or a glossary to define all the symbols and variables used in the paper.** We will add a notation table or glossary in Section 2.\n\n*   **Suggestion 9: Include a discussion of potential biases in the training data and the model's performance across different languages and demographic groups.** We will add a discussion in Section 5 (Conclusion).\n\n*   **Suggestion 10: Add a section on potential misuse cases and mitigation strategies.** We will add a brief discussion in Section 5 (Conclusion).\n\n*   **Suggestion 11: Discuss the potential for the technology to be used for both beneficial and harmful purposes.** We will add a brief discussion in Section 5 (Conclusion).\n\nWe believe these revisions will significantly improve the clarity, rigor, and impact of our paper. Thank you again for your valuable feedback."
  }
]