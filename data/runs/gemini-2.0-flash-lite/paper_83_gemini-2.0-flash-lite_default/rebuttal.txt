[
  {
    "rebuttal": "We thank the reviewer for their thorough and insightful feedback. We appreciate the time taken to review our work and provide constructive criticism. We address each point below:\n\n**Weaknesses:**\n\n*   **Lack of Novelty:** The reviewer notes a lack of clear explanation of novelty. We respectfully disagree. The introduction explicitly states our contributions: \"(1) We demonstrate that the stereotype of 'person' for Stable Diffusion, when no other information about gender is provided in prompts, skews male and ignores nonbinary genders...\" (Section 1). We build on prior work (Bianchi et al., 2023; Fraser et al., 2023) by specifically examining the intersection of gender and nationality stereotypes within Stable Diffusion, a dimension not fully explored in previous studies. We will clarify this further in the revised introduction by explicitly comparing our prompt design and analysis to prior work.\n\n*   **Reproducibility and Environment:** The reviewer points out the lack of a fixed seed and environment details. We acknowledge this is a valid concern. While we intentionally avoided a fixed seed to simulate the user experience (Section 3.2), we will include a section detailing the environment used (Python version, library versions, hardware) to enhance reproducibility. We will also provide the code used for image generation in the supplementary materials.\n\n*   **Overstated Claims:** The reviewer suggests we overstate the claim about the Western, light-skinned man as the default. We believe this is a misinterpretation. Our findings, supported by CLIP-cosine similarity and manual verification, demonstrate a strong bias towards this depiction (Section 4.1). We will revise the language in Section 5.1 to more precisely reflect the strength of our evidence and avoid any overstatements. We do not claim the model's biases are *solely* due to ownership or user base, but rather that these factors, alongside data and design choices, contribute to the observed biases (Section 5.1).\n\n*   **Figure and Table Presentation:** The reviewer notes issues with figure and table clarity. We agree and will address these. Figure 1 already has labels (left to right) indicating the prompts used. We will add labels to the images in Figure 1 to indicate the prompts used. We will add a description of Figure 4 in the main text. We will include standard deviations and confidence intervals for the cosine similarity scores in Tables 3, 4, and 5. We will also add p-values to indicate statistical significance where appropriate.\n\n*   **Metric and Definition Clarity:** The reviewer requests a more detailed explanation of CLIP-cosine similarity and the definition of NSFW. We will add a more detailed explanation of the CLIP-cosine similarity metric, including its formula and interpretation, in Section 3.3. We will define 'NSFW' in Section 3.4, where we introduce the NSFW detector.\n\n*   **Misuse, Failure Modes, and Fairness:** We acknowledge the lack of explicit discussion of misuse scenarios, failure modes, and a detailed fairness analysis. We will add a new section to the discussion to address potential misuse scenarios and propose mitigation strategies. We will also analyze potential failure modes and expand the fairness discussion to address how the model's outputs might differentially affect various demographic groups and propose mitigation strategies.\n\n*   **Dataset License and Usage Restrictions:** We will add explicit license and consent statements for datasets used in the next version of the paper.\n\n**Suggestions:**\n\n*   **Detailed Comparison:** We will include a detailed comparison of the prompts and methodologies used in this work versus prior work in the introduction.\n\n*   **Seed and Environment:** We will report the environment used and provide the code used for image generation in the supplementary materials.\n\n*   **License and Consent Statements:** We will add explicit license and consent statements for datasets used.\n\n*   **Figure and Table Improvements:** We will add labels to the images in Figure 1 to indicate the prompts used. We will include a description of Figure 4 in the main text. We will include standard deviations and confidence intervals for the cosine similarity scores in Tables 3, 4, and 5. We will also add p-values to indicate statistical significance where appropriate.\n\n*   **Metric and Definition Clarity:** We will add a more detailed explanation of the CLIP-cosine similarity metric, including its formula and interpretation. We will define 'NSFW'. We will clarify the exact prompt variations used for gender and nationality analysis.\n\n*   **Misuse, Failure Modes, and Fairness:** We will add a section on potential misuse scenarios and propose mitigation strategies. We will analyze potential failure modes of the model and propose mitigation strategies. We will expand the fairness discussion to address how the model's outputs might differentially affect various demographic groups and propose mitigation strategies.\n\n*   **Broader Impact Section:** We will add a Broader Impact section with mitigation strategies, including data curation from diverse sources, human-centered machine learning approaches, and incorporating annotators from a wide range of cultural contexts."
  }
]