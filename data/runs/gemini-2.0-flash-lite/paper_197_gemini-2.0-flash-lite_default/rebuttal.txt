[
  {
    "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the time and effort invested in reviewing our paper. We address each point below:\n\n**Weaknesses:**\n\n*   **SOTA Comparisons:** The paper claims SOTA performance (Sec 5) but lacks specific comparisons. We respectfully disagree. Section 3.3, Table 1, explicitly compares our method against several SOTA DS-NER baselines: AutoNER, Early Stopping, Negative Sampling, and MPU. We report F1 scores and highlight the improvements over these methods. The reviewer may have overlooked this section. We will clarify this further in the revised version by explicitly stating the SOTA methods we are surpassing in the abstract and introduction.\n\n*   **Computational Complexity:** The paper does not provide sufficient details on the computational complexity. We acknowledge this is partially addressed. While we mention the Sinkhorn-Knopp algorithm's efficiency (Appendix A), we did not explicitly compare the computational cost with other methods. We will add a paragraph in Section 2.2 and Appendix A discussing the time complexity of our method and comparing it with the baselines, including the impact of multiple prototypes.\n\n*   **Reproducibility Details:** The paper lacks crucial details for reproducibility, including random seeds and computational environment. We acknowledge this gap. We will include the random seeds used for all experiments in Appendix B and report the standard deviation across multiple runs in Table 1 and Table 2. We will also provide details about the software environment (PyTorch, Transformers versions, etc.) in Appendix B.\n\n*   **Figure and Table Improvements:** Figure 3 lacks clear axis labels and units, and other figures could benefit from more descriptive captions. Table 1 and Table 3 lack confidence intervals or statistical significance tests. We acknowledge this. We will add axis labels and units to Figure 3 and improve the captions for Figures 4, 5, 7, and 8. We will also include p-values and standard deviations or confidence intervals in Tables 1 and 3.\n\n*   **Bias, Misuse, and Societal Impacts:** The paper does not address potential biases, misuse cases, or broader societal impacts. We acknowledge this is a significant omission. We will add a new section, \"Broader Impact,\" to discuss potential biases in the datasets (e.g., biases related to the dictionaries used for distant supervision), potential misuse cases, and mitigation strategies. We will also discuss data privacy and consent issues, where applicable.\n\n*   **Comparison to BOND:** The paper does not explicitly compare its method against BOND [3]. We acknowledge this omission. We will include BOND as a baseline in our experiments and comparison in the revised version. We will re-implement BOND using the same settings as our other baselines and report the results in Table 1.\n\n**Suggestions:**\n\n*   **Detailed SOTA Comparison:** We will provide a more detailed comparison with other SOTA methods, including quantitative results and discussion of the differences, as mentioned above.\n\n*   **Visualization and Analysis:** We will include more visualizations and detailed analysis to support the claims about intra-class variance and the effectiveness of denoised optimal transport. We believe that Figure 4, Figure 5, Figure 6, and Figure 7 already provide this support, but we will enhance the captions and add more detailed explanations in the text.\n\n*   **Reproducibility Details:** We will include the random seeds and software environment details, as mentioned above.\n\n*   **Figure and Table Improvements:** We will add axis labels, units, legends, error bars, p-values, and standard deviations or confidence intervals, as mentioned above.\n\n*   **Dataset Information and Bias Analysis:** We will provide detailed information about the datasets used, including their sources, licenses, and any relevant usage restrictions. We will analyze the datasets for potential biases and discuss how these biases might affect the model's performance and fairness, as mentioned above.\n\n*   **Misuse and Mitigation:** We will discuss potential misuse cases and consider mitigation strategies to prevent harmful applications of the model, as mentioned above.\n\n*   **Ablation Study of DOT:** We already have an ablation study in Section 3.4 and Table 2, which isolates the impact of the denoised optimal transport algorithm. We will clarify this in the text to ensure the reviewer understands this point. We will also add a more detailed discussion of the results in the ablation study section."
  }
]