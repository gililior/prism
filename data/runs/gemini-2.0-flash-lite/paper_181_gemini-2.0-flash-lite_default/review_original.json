{
  "summary": "This paper investigates the use of self-influence scores for data filtering and automated curriculum learning (AutoCL) to improve NLP model performance. The authors demonstrate the stability of self-influence scores and show that dynamic reweighing with AutoCL outperforms threshold filtering. However, the paper lacks crucial details about datasets, comparisons, and statistical rigor, limiting the generalizability and impact of the findings.",
  "strengths": [
    {
      "kind": "strength",
      "text": "The paper uses established influence function methods (ABIF, TracIn) and curriculum learning techniques, providing a solid methodological foundation.",
      "grounding": "Sec 2.3",
      "facet": "methods"
    },
    {
      "kind": "strength",
      "text": "The authors demonstrate the stability of Arnoldi iteration-based self-influence scores with respect to training hyperparameters (Section 7) and show that dynamic reweighing based on multi-armed bandits outperforms threshold filtering on noisy and clean datasets (Section 7).",
      "grounding": "Section 7",
      "facet": "claims_vs_evidence"
    },
    {
      "kind": "strength",
      "text": "The paper proposes a data filtering automation method using bandit AutoCL to dynamically detect harmful or useful training data quantiles (Intro, §1.3, §5), and investigates the stability of self-influence scores, which is a prerequisite for data filtering and scheduling, and analyzes their efficacy in capturing outliers (Intro, §1.3).",
      "grounding": "Intro, §1.3, §5",
      "facet": "originality"
    },
    {
      "kind": "strength",
      "text": "The paper references the use of released code for influence computation (ABIF) (Section 2.3) and provides clear visualizations (Fig 1) and a well-structured table (Table 2).",
      "grounding": "Section 2.3, Fig 1, Table 2",
      "facet": "code/data availability, figures, tables"
    },
    {
      "kind": "strength",
      "text": "The paper builds upon the work of Feldman and Zhang (2020) [1] by using self-influence scores for data cleaning and extends this by investigating the efficacy of these scores in capturing outliers and improving downstream performance across multiple tasks (machine translation, question answering, and text classification) (Intro).",
      "grounding": "Intro",
      "facet": "novelty"
    }
  ],
  "weaknesses": [
    {
      "kind": "weakness",
      "text": "The paper lacks details on the specific datasets used for evaluation, making it difficult to assess the generalizability of the findings, and the conclusion overstates the generality of the method without providing specific details on the datasets or tasks (Section 7).",
      "grounding": "Section 7",
      "facet": "claims_vs_evidence"
    },
    {
      "kind": "weakness",
      "text": "The paper needs to clearly articulate the delta compared to existing methods for self-influence calculation and AutoCL (Related Work, §6), and lacks a clear comparison with other data cleaning methods, especially in terms of downstream task performance (Sec 4, Sec 5).",
      "grounding": "Related Work, §6, Sec 4, Sec 5",
      "facet": "positioning, comparative evidence"
    },
    {
      "kind": "weakness",
      "text": "The paper does not mention the use of seeds for the experiments, and lacks details on the environment used for the experiments (Section 2.3), making reproducibility difficult.",
      "grounding": "Section 2.3",
      "facet": "seeds/variance, environment reproducibility"
    },
    {
      "kind": "weakness",
      "text": "The paper lacks crucial statistical information such as confidence intervals, p-values, or clear indications of the number of trials or repetitions (Tables 1, 3, 4, 5, 6, 7, 8, 9), and lacks a thorough discussion of potential risks, including misuse, fairness, and broader societal impacts (Insufficient evidence).",
      "grounding": "Tables 1, 3, 4, 5, 6, 7, 8, 9, Insufficient evidence",
      "facet": "tables, societal_impact"
    },
    {
      "kind": "weakness",
      "text": "The term 'outliers' is used as an umbrella term, but the specific characteristics of each type (label noise, out-of-distribution, ambiguous, difficult-to-learn) could be clarified further, perhaps with examples (Abstract, §1), and the paper could benefit from a more detailed explanation of Influence Functions (IFs) and self-influence scores, especially for readers unfamiliar with the concept (§1.1).",
      "grounding": "Abstract, §1, §1.1",
      "facet": "clarity_presentation"
    },
    {
      "kind": "weakness",
      "text": "No information on dataset licensing, consent, privacy, or usage terms is provided, and ethical risks associated with the datasets are not discussed (Insufficient evidence).",
      "grounding": "Insufficient evidence",
      "facet": "ethics_licensing, ethics_risks"
    },
    {
      "kind": "weakness",
      "text": "The paper does not explicitly compare the performance of its proposed method with the self-ensembling approach of Nguyen et al. (2020) [2] or the dataset cartography approach of Swayamdipta et al. (2020) [3] (Related Work).",
      "grounding": "Related Work",
      "facet": "comparison"
    }
  ],
  "suggestions": [
    {
      "kind": "suggestion",
      "text": "Provide more details on the datasets and tasks used in the experiments to better support the claims of generality (Section 7), and include a direct comparison with a state-of-the-art data cleaning method on the same datasets and tasks (Sec 4, Sec 5).",
      "grounding": "Section 7, Sec 4, Sec 5",
      "facet": "claims_vs_evidence, comparative evidence"
    },
    {
      "kind": "suggestion",
      "text": "Provide ablation studies to show the contribution of each component (self-influence, AutoCL) to the overall performance (Sec 4, Sec 5), and release the code used for the experiments, including the scripts and the environment file (e.g., conda environment.yml or Dockerfile) (All sections).",
      "grounding": "Sec 4, Sec 5, All sections",
      "facet": "comparative evidence, code/data availability, environment reproducibility"
    },
    {
      "kind": "suggestion",
      "text": "Specify the random seeds used for all experiments and report the variance (e.g., standard deviation) across multiple runs (Section 2.3), and include standard deviations or confidence intervals for all reported metrics. Add p-values to indicate the statistical significance of the differences between different methods or settings, especially in Table 3 (Tables 2, 3, 4, 5, 6, 7, 8).",
      "grounding": "Section 2.3, Tables 2, 3, 4, 5, 6, 7, 8",
      "facet": "seeds/variance, tables"
    },
    {
      "kind": "suggestion",
      "text": "Include a section detailing the datasets used, their licenses, terms of use, and any relevant consent information (Insufficient evidence), and address potential privacy concerns and ethical risks associated with the data (Insufficient evidence).",
      "grounding": "Insufficient evidence",
      "facet": "ethics_licensing, ethics_risks"
    },
    {
      "kind": "suggestion",
      "text": "Provide concrete examples of how self-influence scores are calculated or used in the context of the research questions (§1.1, RQ1, RQ2), and define all acronyms when they first appear (e.g., AutoCL) (Abstract, §1.2).",
      "grounding": "§1.1, RQ1, RQ2, Abstract, §1.2",
      "facet": "clarity_presentation"
    },
    {
      "kind": "suggestion",
      "text": "Include a section on potential misuses of the proposed method, such as its application to generate biased or misleading information. Discuss how the method could be used to amplify existing biases in the data (Insufficient evidence), and analyze the fairness implications of the method. Consider how the method might affect different demographic groups if applied to datasets containing sensitive information. Discuss potential biases in the data and how the method might exacerbate them (Insufficient evidence).",
      "grounding": "Insufficient evidence",
      "facet": "societal_impact"
    },
    {
      "kind": "suggestion",
      "text": "Conduct a head-to-head comparison with Nguyen et al. (2020) [2] and Swayamdipta et al. (2020) [3] on the same datasets used in the current paper (machine translation, question answering, and text classification). Evaluate the performance on both in-distribution and out-of-distribution test sets to assess generalization (Related Work), and include an ablation study comparing the proposed method with a baseline that uses confidence scores or label noise detection for data cleaning. This will help to isolate the contribution of self-influence scores (Sec 4.1).",
      "grounding": "Related Work, Sec 4.1",
      "facet": "experiment"
    }
  ],
  "scores": null,
  "overall": null,
  "confidence": null
}