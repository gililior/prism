[
  {
    "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the time and effort invested in reviewing our paper. We address each point below:\n\n**Weaknesses:**\n\n*   **Methods Section - Statistical Tests:** The reviewer requests details on statistical tests. We respectfully disagree that this is missing. Our method relies on the comparison of the concentration parameter (Îº), which is derived from the norm of the mean word vector. The core of our method is the coverage score (Equation 1) which is a ratio of these parameters. We use the K-means++ algorithm to determine the threshold for binary classification in the SemEval-2020 Task 1 (Section 3.1). We believe the method is clearly described in Section 2 and the evaluation in Section 3.2. We will clarify this further in the revised version.\n\n*   **Reproducibility - Seeds and Variance:** The reviewer points out the lack of information on seeds and variance. We acknowledge this is missing. We will include the random seeds used for the K-means++ algorithm in Section 3.1 and report the standard deviation of the results across multiple runs where applicable in the revised version.\n\n*   **SemEval-2020 Task 1 Comparison - Specifics:** The reviewer requests more detail on the SemEval-2020 Task 1 comparison. We state in the Introduction that our method \"rivals the best-performing system.\" We provide the detection accuracy in Table 2, which shows our method's performance compared to the best-performing system (Rother et al., 2020). We will add a sentence to clarify the delta in performance in the revised version.\n\n*   **Generalizability - Corpus Pair Applicability:** The reviewer questions the substantiation of our claim regarding applicability to corpus pairs where previous methods' assumptions do not hold. We believe this is demonstrated in Section 3.4 and 3.5, where we analyze native vs. non-native English (ICNALE) and compare Chinese and Japanese learners of English. These scenarios do not have word alignment, which is a limitation of previous methods. We will add a sentence explicitly stating this advantage in Section 6.\n\n*   **LLM Limitations:** The reviewer is correct that our method's generalizability is limited by the availability and quality of LLMs. This is acknowledged in Section 6, where we discuss the limitations of our approach. We will add a sentence to emphasize this limitation and suggest future work on languages with limited LLM support.\n\n*   **Dataset License and Usage Restrictions:** We acknowledge the lack of dataset license and usage restrictions. We will add explicit license and consent statements for datasets used in the revised version.\n\n*   **Figure 3 - Axis Labels:** The reviewer is correct that Figure 3 lacks clear axis labels. We will add axis labels and units to Figure 3 in the revised version.\n\n*   **Tables 3-8 - Statistical Information:** The reviewer requests statistical information such as standard deviation, confidence intervals, or p-values. We acknowledge this is missing. We will include standard deviations or confidence intervals for the word frequencies (fS and fT) and add p-values to indicate statistical significance of the frequency differences in Tables 3-8 in the revised version. We will also include the number of tokens, types, and other relevant statistics in Table 1.\n\n*   **Misuse Scenarios and Failure Modes:** We acknowledge the lack of explicit discussion on potential misuse scenarios and failure modes. We will add a section discussing potential misuse cases in the revised version.\n\n*   **Fairness Considerations:** We acknowledge the lack of discussion on fairness considerations. We will add a section discussing fairness considerations in the revised version.\n\n*   **Societal Impacts:** We acknowledge the lack of a dedicated section on broader societal impacts. We will add a section detailing the broader societal impacts in the revised version.\n\n**Suggestions:**\n\n*   **Evaluation Metrics:** We believe the evaluation metrics are explained in Section 3.1 and 3.2. We will add a sentence to clarify the statistical properties of the evaluation metrics in Section 4.\n\n*   **Code Repository:** We will provide a link to the code repository, including the code and scripts used for the experiments, and include a requirements file (e.g., `requirements.txt` or `environment.yml`) to specify the necessary dependencies and their versions.\n\n*   **Detailed SemEval-2020 Comparison:** We will add a sentence to clarify the delta in performance in the revised version.\n\n*   **Computational Efficiency Analysis:** We believe the computational efficiency is discussed in Section 4. We will add specific runtime measurements in the revised version.\n\n*   **Types of Semantic Differences:** We believe the types of semantic differences are discussed in Section 3.3, 3.4, and 3.5. We will add more examples and interpretations in Section 4.\n\n*   **LLM Performance Experiments:** We will conduct experiments on languages or corpora where the LLM is known to perform poorly to demonstrate the limitations of the method.\n\n*   **Notation Table:** We will add a table of notation to define all symbols used in the revised version.\n\nWe believe that addressing these points will significantly improve the clarity and impact of our paper. Thank you again for your valuable feedback."
  }
]