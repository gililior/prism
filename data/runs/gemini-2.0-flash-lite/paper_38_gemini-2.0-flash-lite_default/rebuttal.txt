[
  {
    "rebuttal": "We sincerely thank the reviewer for their insightful and detailed feedback, which has helped us identify areas for improvement in our paper. We address each point below:\n\n**Weaknesses:**\n\n*   **Weakness 1:** \"The paper's claim of CACAO learning a rich and complete context-type semantic space lacks direct evaluation and supporting evidence.\" (Sec 4.3) \n    *   **Response:** We respectfully disagree. Section 4.3, particularly the discussion of the overall results, provides evidence supporting this claim. Specifically, point (2) in Section 4.3 states, \"Our CACAO performs well not only on novel types but also on base types. It indicates that CACAO can learn a rich and complete context-type semantic space, and expand its vocabulary from large-scale pre-training.\" Furthermore, the improved performance on both base and novel types, as shown in Table 1, indirectly validates this claim. The reviewer may have overlooked this section.\n\n*   **Weakness 2:** \"The paper does not provide sufficient information on the datasets used for pre-training and fine-tuning, including details about the context-type pairs.\" (Abstract) \n    *   **Response:** This is a valid point. While we mention the use of Wikipedia articles and anchors for pre-training and OntoNotes 5.0 and FEW-NERD for fine-tuning, we acknowledge that more detail is needed. We will expand the abstract and Section 3.1 to include the source, size (80M context-type pairs), and characteristics of the pre-training data, including how context-type pairs are constructed from Wikipedia articles and Wikidata. We will also clarify the data splits used for the OVNER benchmarks in Appendix A.\n\n*   **Weakness 3:** \"The paper lacks a detailed comparison with the most relevant and recent baselines in the OVNER or related fields, and the delta between CACAO and the closest performing method is not clearly explained.\" (Related Work, Sec 4.1) \n    *   **Response:** We believe the paper already addresses this to a reasonable extent. Section 4.2 details the baseline methods, including MRC, BEM, and SMXM, which are relevant to zero-shot NER. Section 4.3 clearly states the performance improvements over the state-of-the-art model SMXM (1.8%, 9.7%, and 9.5% improvements on the three benchmarks). We will enhance the discussion in Section 4.3 to provide a more in-depth analysis of the performance differences, including a comparison of the architectural differences between CACAO and SMXM.\n\n*   **Weakness 4:** \"The paper does not explicitly state the random seeds used for experiments, nor does it provide information on the variance across the random seeds, hindering reproducibility.\" (Section 4.1) \n    *   **Response:** We acknowledge this omission and will rectify it. We will explicitly state the random seeds used for all experiments in Section 4.1 and report the standard deviation across the seeds in Tables 1 and 5 to improve reproducibility.\n\n*   **Weakness 5:** \"Figures 3 and 4 lack clear axis labels, units, and legends, making it difficult to interpret the results. Table 1 and 5 lack information on the variance of the results and statistical significance tests.\" (Fig 3, Fig 4, Table 1, Table 5) \n    *   **Response:** We agree and will revise Figures 3 and 4 to include clear axis labels, units, and legends. We will also add standard deviations and p-values to Tables 1 and 5 to indicate statistical significance.\n\n*   **Weakness 6:** \"The paper does not address potential biases in the training data or the model's outputs, nor does it discuss potential misuse cases.\" (Insufficient evidence) \n    *   **Response:** This is a crucial point. We will add a new section to the paper discussing potential biases in the training data (e.g., biases in Wikipedia content) and their potential impact on the model's performance across different demographic groups. We will also include a discussion of potential misuse cases and mitigation strategies.\n\n**Suggestions:**\n\n*   **Suggestion 1:** \"Provide the specific random seeds used for all experiments and report the variance (e.g., standard deviation) across the seeds to improve reproducibility.\" (Section 4.1) \n    *   **Response:** This suggestion aligns with our response to Weakness 4, and we will implement it.\n\n*   **Suggestion 2:** \"Release the code and the environment setup (e.g., a Dockerfile or a requirements.txt file) to ensure reproducibility.\" (Appendix B) \n    *   **Response:** We plan to release the code and environment setup upon acceptance, as stated in the Ethics Statement.\n\n*   **Suggestion 3:** \"Include a head-to-head comparison with a state-of-the-art method that addresses a similar problem, such as a recent zero-shot or few-shot NER approach, and analyze the performance differences.\" (Sec 4.1) \n    *   **Response:** We believe our current baselines (MRC, BEM, and SMXM) are relevant and competitive. We will strengthen the analysis in Section 4.3 to highlight the differences between CACAO and SMXM, the closest performing method. We will also consider adding a more recent zero-shot or few-shot NER approach if it is directly comparable and available.\n\n*   **Suggestion 4:** \"Provide more details about the pre-training data, including its source, size, and characteristics.\" (Abstract) \n    *   **Response:** This suggestion aligns with our response to Weakness 2, and we will implement it.\n\n*   **Suggestion 5:** \"Add axis labels and a legend to Figures 3 and 4, and include standard deviations or confidence intervals in Tables 1-5. Add p-values to indicate statistical significance.\" (Fig 3, Fig 4, Tables 1-5) \n    *   **Response:** This suggestion aligns with our response to Weakness 5, and we will implement it.\n\n*   **Suggestion 6:** \"Include a discussion of potential biases in the training data and their impact on the model's performance across different demographic groups, and add a section on potential misuse cases and mitigation strategies.\" (Insufficient evidence) \n    *   **Response:** This suggestion aligns with our response to Weakness 6, and we will implement it.\n\nWe believe that addressing these points will significantly improve the clarity, rigor, and impact of our paper. We are grateful for the reviewer's guidance and are committed to incorporating these suggestions in the revised version."
  }
]