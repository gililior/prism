[
  {
    "rid": "StwZBvrzNp",
    "reviewer": null,
    "report": {
      "paper_topic_and_main_contributions": "The work conducted a noise audit of nine offensive speech classifiers on a dataset of more than 92 million YouTube comments, revealing considerable variations in the results. Also, it annotated a dataset with views from people from different political parties regarding their perception of offense and also about vicarious offense, that is, to predict offense for others who do not share the same political belief. Finally, it analyzed human and machine moderators' agreement on what is offensive.",
      "reasons_to_accept": "- The release of a novel dataset that can be valuable for further research regarding vicarious offense.\n- The annotation process is well explained.\n- Experimental evaluation is complete: comparing machine and human moderators, generating informative results, and discussing the impact of what was achieved.",
      "reasons_to_reject": "- Since each machine moderator is trained on a different dataset, they are expected to have a low agreement. Training on a concatenation of datasets or evaluating more public APIs, such as Perspective API, would generate more informative noise audit results.\n- Some presentation problems make the last two sections difficult to follow. I suggested improvements in the corresponding section from review.",
      "typos_grammar_style_and_presentation_improvements": "- Please cite the Appendix subsections in the paper so we can refer easily to them.\n- Table 1 is not cited in the paper.\n- Line 381: The cited result (0.43) is extracted from the Appendix. Consider reorganizing so the result appears in the main paper.\n- Figure 3 caption is incorrect. A cell [i, j] is not referring to machine moderators' agreement since the figure is also showing human moderators' agreement.\n- Line 478: Figure reference is missing.\n- Figure 4 uses a different vicarious offense notation from what was previously explained in the paper (in lines 401-404).\n- The results using ChatGPT to predict the vicarious offense are in the Discussion and Conclusion section, which should be in the Results section.\n- In the Appendix, Figures 5, 6, and 7 are not cited.\n- In the Appendix, Section B.1 is empty.",
      "ethical_concerns": "No"
    },
    "scores": {
      "soundness": "4: Strong: This study provides sufficient support for all of its claims/arguments. ",
      "excitement": "4: Strong: This paper deepens the understanding of some phenomenon or lowers the barriers to an existing research direction.",
      "reproducibility": "4: Could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method."
    },
    "meta": {
      "license": "CC BY 4.0",
      "reviewer_confidence": "4: Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
    }
  },
  {
    "rid": "2nnMLbf8jr",
    "reviewer": null,
    "report": {
      "paper_topic_and_main_contributions": "This work operates in the domain of political discourse, performing a large-scale study on the perception of offense from across the political spectra as well as from machine moderators. Further, a dataset produced by their study is released, labeled additionally for \"vicarious offense\".",
      "reasons_to_accept": "1. A novel study analyzing perceptions of offense from different political spectra, as well as alignment with machine learning models. This study is vital in current political discourse and discussion on hate speech.\n2. Description of crowdsourced annotators is thorough and gives a solid picture of the annotator pool.\n3. The list of machine moderators is extensive, leading to a thorough analysis.\n4. Findings are interesting and the experiments conducted robustly.",
      "reasons_to_reject": "Nothing significant. See questions for comments/suggestions for improvement.",
      "questions_for_the_authors": "1. I was wondering whether it would be useful to add an example case of vicarious offense in the introduction to better showcase this concept. Even though the definition is adequate, this is a new concept and would therefore benefit from a readily available example. Maybe you could repurpose the Fig. 1 caption to specifically point out what vicarious offense is.\n2. Can this study have a temporal element as well? It would be interesting to see how the findings evolve throughout the years.\n3. Is there a reason you did not use the Perspective API? You did use TCC (model 8 in your list), but I am wondering why the Perspective API was avoided. While I am not advocating for its use, a lot of contemporary work uses it so I found this decision interesting. If there is an explicit reason behind this, including it in the paper would be informative.\n4. For RQ2, I would have liked to have seen self-alignment as a baseline: what is the alignment within Democrats (Dem^Dem)? How well are Democrats at predicting what other Democrats find offensive? This would be interesting as a comparison.",
      "missing_references": "There are two works that perform studies on offense in political discourse: 1. Hate Towards the Political Opponent: A Twitter Corpus Study of the 2020 US Elections on the Basis of Offensive Speech and Stance Detection, Lara Grimminger, Roman Klinger, 2021. ( work collects offensive tweets from democrats and republicans targeting the other community) 2. Listening to Affected Communities to Define Extreme Speech: Dataset and Experiments, Antonis Maronikolakis, Axel Wisiorek, Leah Nann, Haris Jabbar, Sahana Udupa, Hinrich Schuetze, 2022. ( one of the domains examined is hate speech in political discourse, collecting data targeting politicians, state, civil rights advocates, etc.)\nWhile these two differ from this work since they only collect data for hate speech in political discourse and do not perform a noise audit, I find they are still pertinent (slightly contradicting lines 167-169).",
      "typos_grammar_style_and_presentation_improvements": "lines 193 and 210 and 232: Usually footnotes are added after punctuation for more compact text. Such as this: text.1",
      "ethical_concerns": "No"
    },
    "scores": {
      "soundness": "4: Strong: This study provides sufficient support for all of its claims/arguments. ",
      "excitement": "4: Strong: This paper deepens the understanding of some phenomenon or lowers the barriers to an existing research direction.",
      "reproducibility": "3: Could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined; the training/evaluation data are not widely available."
    },
    "meta": {
      "license": "CC BY 4.0",
      "reviewer_confidence": "4: Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
    }
  },
  {
    "rid": "LEA1pFGI0Q",
    "reviewer": null,
    "report": {
      "paper_topic_and_main_contributions": "The paper focuses on first-person offense and vicarious offense in US-based political conversations. The paper then investigates 3 research questions based on the alignment between machine-machine, human-human, and machine-human moderators to identify first-person and vicarious offense present in the conversations.",
      "reasons_to_accept": "The idea is interesting and exciting. \nThe need to focus on vicarious offense is indeed important from the societal point of view. \nResults and discussions are properly backed by political theories. \nThe comparison of human-human moderators is well discussed and presented. \nOverall, the writing of the paper is impressive as it is well written and understood easily.",
      "reasons_to_reject": "I am not convinced how authors have claimed about machine moderators. I feel that not enough importance is given to the preparation of machine moderators. Similar architectures of BERT /RoBERTa models are trained on different datasets and used as machine moderators to evaluate their performance on unseen political data. Due to the very simple architecture and the fact that I think these datasets are general datasets (with high imbalance) that are not entirely based on political data, it is possible that these models do not perform well on first-person offense detection and therefore have not been well aligned. I like that the authors in the discussion section used ChatGPT for identifying vicarious offense, but they have not shown how ChatGPT performs in identifying first-person offense compared to the models used in the study. Nevertheless, major claims are made about the inability of machine moderators to identify offense. In my opinion, these claims need to be backed up by better models, APIs such as Perspective API, or recent open-source/APIs-based large language models.",
      "questions_for_the_authors": "A. What is the motivation to use the generic datasets for the special case of identifying offenses in US-based political conversations? It is possible models may not learn well because the datasets do not provide enough information related to democrats, republicans, and independent groups based offense.\nB. Do the authors try to use few-shot ChatGPT/Perspective API or other open-source APIs for vicarious and first-person offense identification? It is possible the results might be changed greatly. However, it is still a possibility that can be understood after running the experiments.",
      "missing_references": "None in my opinion.",
      "typos_grammar_style_and_presentation_improvements": "I think that the illustrations and tables should be better placed. The figures that are mentioned on one page are located after 2 pages, which sometimes makes it difficult to follow them. It is always better to place the tables and figures before you mention them.\nTypos: Figure ?? in section 5.3 A.4, B.1 only headings are mentioned",
      "ethical_concerns": "No"
    },
    "scores": {
      "soundness": "3: Good: This study provides sufficient support for its major claims/arguments, some minor points may need extra support or details.",
      "excitement": "4: Strong: This paper deepens the understanding of some phenomenon or lowers the barriers to an existing research direction.",
      "reproducibility": "4: Could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method."
    },
    "meta": {
      "license": "CC BY 4.0",
      "reviewer_confidence": "4: Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
    }
  }
]