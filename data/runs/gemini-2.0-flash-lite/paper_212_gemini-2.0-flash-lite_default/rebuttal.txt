[
  {
    "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the effort taken to thoroughly evaluate our work. We address each point below:\n\n**Weaknesses:**\n\n*   **Weakness 1:** \"The paper lacks a detailed comparison of USB with existing benchmarks...\" We respectfully disagree. The introduction (Section 1) and the related work section (Section 8) both discuss existing benchmarks and highlight the key differences with USB. Section 1 mentions existing benchmarks like those by Nallapati et al. (2016), Narayan et al. (2018), and Wang and Ling (2016), and then emphasizes how USB addresses shortcomings in factuality and controllability. Section 8 provides a more in-depth comparison, noting that many existing datasets are heuristically created, leading to poor-quality reference summaries, while USB uses manual annotation. We believe the reviewer may have overlooked these sections. For the next version, we will add a table summarizing these comparisons, as suggested.\n\n*   **Weakness 2:** \"The paper lacks crucial information for reproducibility...\" We acknowledge this gap. We will include the random seeds used for all experiments in the next version. We will also provide a link to our code repository, including training and evaluation scripts, and specify the hardware used for training and inference. (Sec 3.1)\n\n*   **Weakness 3:** \"Figure 3 lacks clear axis labels and units, and Figures 5 and 6 lack descriptive captions...\" We acknowledge this and will address it in the next version. We will add clear axis labels and units to Figure 3 and provide descriptive captions for Figures 5 and 6.\n\n*   **Weakness 4:** \"The paper lacks a clear definition of 'moderately-sized' models...\" The term \"moderately-sized\" is used in the abstract and introduction. We will clarify this by providing the specific parameter counts of the models used in the next version. The heuristics used for generating synthetic data are described in Section 7, where we outline the methods used for lexical overlap, entity overlap, and error injection.\n\n*   **Weakness 5:** \"Table 3 lacks clear statistical measures...\" We acknowledge the lack of statistical measures in Table 3 and Tables 6-9. We will include inter-annotator agreement metrics (e.g., Cohen's Kappa) in Table 3 in the next version. We will also consider adding a column to Tables 6-9 to indicate the purpose of each instruction.\n\n*   **Weakness 6 & 7:** \"The paper does not address dataset licensing...\" We acknowledge this critical omission. We will include a clear statement of the dataset license (CC BY-SA for Wikipedia content) and usage terms. We will also add a section addressing privacy implications, potential risks, misuse cases, fairness considerations, and a Broader Impact section in the next version.\n\n**Suggestions:**\n\n*   **Suggestion 1:** \"Include a table comparing USB with existing benchmarks...\" We agree and will incorporate this as described above.\n\n*   **Suggestion 2:** \"Provide a more detailed analysis of the performance of different models...\" We believe Section 5 already provides a detailed analysis. We will consider expanding this further in the next version.\n\n*   **Suggestion 3:** \"Include the random seeds...\" We will incorporate this as described above.\n\n*   **Suggestion 4:** \"For Figure 3, label the axes clearly...\" We will incorporate this as described above.\n\n*   **Suggestion 5:** \"Provide a table summarizing the eight tasks...\" We believe that Section 3 already defines the tasks. We will consider adding a table summarizing the tasks and evaluation metrics in the next version.\n\n*   **Suggestion 6:** \"For Table 3, include inter-annotator agreement metrics...\" We will incorporate this as described above.\n\n*   **Suggestion 7:** \"Include a clear statement of the dataset license...\" We will incorporate this as described above.\n\n*   **Suggestion 8:** \"Provide a clear statement about the intended use...\" We will incorporate this as described above.\n\n*   **Suggestion 9:** \"Conduct a head-to-head comparison with [2] (QAFactEval)...\" We will consider this for future work, as it requires significant additional experimentation. We will also evaluate the robustness of our models against input noise in future work."
  }
]