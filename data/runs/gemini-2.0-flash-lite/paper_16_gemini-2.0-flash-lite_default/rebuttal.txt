{
  "rebuttal": [
    {
      "reviewer_feedback": "Weakness: The paper overclaims the generalizability of CARP without providing sufficient evidence for all datasets or settings. Performance on MR is comparable to SOTA, not a clear improvement. (Sec 5.2)",
      "response": "We acknowledge the reviewer's concern regarding overclaiming. While CARP achieves new SOTA results on four out of five benchmarks, we agree that the performance on MR (Movie Review) is comparable to SOTA, not a clear improvement. We will revise the abstract and conclusion to reflect this nuance more accurately. We will also emphasize the strong performance of CARP in low-resource and domain adaptation settings, which demonstrates its generalizability in challenging scenarios. (See Section 5.3 and 5.4)"
    },
    {
      "reviewer_feedback": "Weakness: The paper lacks a detailed ablation study to isolate the impact of individual components of CARP, making it difficult to assess the contribution of each part. (Insufficient evidence)",
      "response": "We respectfully disagree. Section 6.2 and Table 4 provide a detailed ablation study. We systematically removed components (text, clues, reasons, label) from the demonstrations to assess their individual impact on the SST-2 dataset. We believe this provides sufficient evidence to understand the contribution of each part of CARP. We will clarify the description of this section to ensure it is not overlooked."
    },
    {
      "reviewer_feedback": "Weakness: The paper lacks a detailed comparison with existing prompting techniques for LLMs in text classification, and the delta compared to existing methods is not clearly articulated. (Related Work)",
      "response": "We believe the paper already provides a detailed comparison with existing prompting techniques. We compare CARP with the vanilla prompting method and the Chain-of-Thought (CoT) prompting method (Kojima et al., 2022) across all datasets. The results are presented in Table 1 and Table 2. We will enhance the discussion in the introduction and related work sections to more clearly articulate the differences and advantages of CARP compared to these baselines."
    },
    {
      "reviewer_feedback": "Weakness: The paper does not provide sufficient details on the fine-tuning process of the model used for demonstration search, making it difficult to assess the impact of this component. (Abstract, Intro)",
      "response": "We acknowledge this point and will expand on the details of the fine-tuning process. We will add more specifics about the fine-tuning hyperparameters, including the learning rate, batch size, and optimizer used in Section G.2. This will allow readers to better assess the impact of this component."
    },
    {
      "reviewer_feedback": "Weakness: The paper does not explicitly state the random seeds used for experiments, hindering reproducibility. (Sec 3.1, Table 1, Table 2)",
      "response": "We acknowledge the importance of reproducibility. We will add a sentence in Section 3.1 to state that we used specific random seeds for all experiments. We will also include the specific seeds used in the Appendix."
    },
    {
      "reviewer_feedback": "Weakness: The paper does not provide details on the environment used for the experiments, such as the specific versions of libraries and the hardware used. (All sections)",
      "response": "We will add a section in the Appendix detailing the experimental environment. This will include the specific versions of the libraries (e.g., PyTorch, Transformers), the operating system, and the hardware used (e.g., GPU model).",
      "response_type": "add"
    },
    {
      "reviewer_feedback": "Weakness: Figures 3 and 4 lack clear axis labels and units, making it difficult to interpret the visualizations. (Fig 3, Fig 4)",
      "response": "Figures 3 and 4 are examples of prompts and do not have axes. We will clarify the captions to avoid any confusion."
    },
    {
      "reviewer_feedback": "Weakness: The paper lacks a dedicated section for notation, making it difficult to quickly understand the symbols and abbreviations used. (Throughout the paper)",
      "response": "We will add a dedicated section for notation in the Appendix to clarify the symbols and abbreviations used throughout the paper."
    },
    {
      "reviewer_feedback": "Weakness: Tables lack standard deviations, confidence intervals, or p-values to assess the statistical significance of the results. Some tables lack clear headers and descriptions. (Tables 1, 2, 3, 4, 5, 7)",
      "response": "We will add standard deviations to all tables. We will also add confidence intervals and p-values where appropriate to assess the statistical significance of the results. We will review all table headers and descriptions to ensure clarity."
    },
    {
      "reviewer_feedback": "Weakness: The paper does not address fairness considerations, such as how the model's performance might vary across different demographic groups or sensitive topics. (Insufficient evidence)",
      "response": "We acknowledge the importance of fairness considerations. We will add a section in the discussion to address potential biases in the LLMs and datasets used and how these biases might affect the model's performance and fairness. We will also discuss the limitations of our work in this regard.",
      "response_type": "add"
    },
    {
      "reviewer_feedback": "Weakness: The paper lacks a dedicated section on broader impacts, including the potential societal consequences of the model. (Insufficient evidence)",
      "response": "We will add a Broader Impact section to discuss the potential societal consequences of the model and its applications.",
      "response_type": "add"
    },
    {
      "reviewer_feedback": "Suggestion: Conduct ablation studies to isolate the impact of each component of CARP (clue extraction, reasoning, and demonstration search). (Insufficient evidence)",
      "response": "We believe this suggestion is addressed by the ablation study in Section 6.2 and Table 4. We will clarify the description of this section to ensure it is not overlooked."
    },
    {
      "reviewer_feedback": "Suggestion: Conduct a comparative analysis with other prompting methods (e.g., chain-of-thought prompting) on the same datasets to demonstrate the effectiveness of CARP. (Related Work, Sec 4.1)",
      "response": "We believe this suggestion is already addressed. We compare CARP with the vanilla prompting method and the Chain-of-Thought (CoT) prompting method (Kojima et al., 2022) across all datasets. The results are presented in Table 1 and Table 2."
    },
    {
      "reviewer_feedback": "Suggestion: Specify the random seeds used for all experiments and report the standard deviation or confidence intervals along with the mean results. (Sec 3.1, Table 1, Table 2)",
      "response": "We will specify the random seeds used for all experiments and report the standard deviation or confidence intervals along with the mean results, as suggested."
    },
    {
      "reviewer_feedback": "Suggestion: Detail the hardware and software environment used for the experiments, including the specific versions of the libraries (e.g., PyTorch, Transformers) and the operating system. (All sections)",
      "response": "We will add a section in the Appendix detailing the experimental environment, including the specific versions of the libraries and the hardware used."
    },
    {
      "reviewer_feedback": "Suggestion: Add clear labels to the axes in Figures 3 and 4, specifying what is being measured (e.g., accuracy, loss) and the units. (Fig 3, Fig 4)",
      "response": "Figures 3 and 4 are examples of prompts and do not have axes. We will clarify the captions to avoid any confusion."
    },
    {
      "reviewer_feedback": "Suggestion: Include standard deviations or confidence intervals to show result variance. Add p-values to indicate the statistical significance of the performance differences between methods. Ensure all table headers are clear and descriptive. (Tables 1, 2, 3, 4, 5, 7)",
      "response": "We will include standard deviations or confidence intervals to show result variance. We will add p-values to indicate the statistical significance of the performance differences between methods. We will ensure all table headers are clear and descriptive."
    },
    {
      "reviewer_feedback": "Suggestion: Add a section discussing potential biases in the LLMs and datasets used, and how these biases might affect the model's performance and fairness. (Insufficient evidence)",
      "response": "We will add a section discussing potential biases in the LLMs and datasets used, and how these biases might affect the model's performance and fairness."
    },
    {
      "reviewer_feedback": "Suggestion: Add a Broader Impact section to discuss the potential societal consequences of the model and its applications. (Insufficient evidence)",
      "response": "We will add a Broader Impact section to discuss the potential societal consequences of the model and its applications."
    }
  ]
}