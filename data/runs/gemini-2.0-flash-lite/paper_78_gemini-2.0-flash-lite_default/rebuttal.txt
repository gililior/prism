{
  "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the time and effort invested in reviewing our paper. We address each point below:\n\n**Weaknesses:**\n\n*   **Detailed comparison with existing scene graph-based methods:** The reviewer requests a more detailed comparison with existing scene graph-based methods. We respectfully disagree that this is entirely missing. Our paper already provides a comparison with related works in Section 2, \"Related Work,\" where we discuss scene graph applications and their limitations. We also compare our approach with NegCLIP, which is a strong baseline. We will expand this section in the revision to include a more direct comparison with scene graph-based methods, highlighting the specific advantages of our approach, particularly in terms of the coarse-to-fine contrastive learning framework and the novel negative mining techniques. We will also add a table summarizing the key differences.\n\n*   **Seeds and Variance:** The reviewer points out the lack of seed information and variance reporting. We acknowledge this omission. We have now included the random seeds used for all fine-tuning experiments in Appendix D.2 and H.1. We have also added standard deviations for the fine-tuning results on the CC-FT dataset in Table 14, and we will include standard deviations for other fine-tuning results in the revision. We do not run multiple pre-training experiments since they are significantly more costly.\n\n*   **Software Environment:** The reviewer notes the absence of software environment details. We acknowledge this. We will provide a link to our code repository in the final version and include a `requirements.txt` file to specify the software environment, as suggested.\n\n*   **Figure Clarity:** The reviewer points out the lack of clear axis labels and legends in some figures. We acknowledge this and will add clear labels to the axes and include legends to identify different methods or experimental settings in Figures 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, and 14. We will also consider using error bars to indicate variance where appropriate.\n\n*   **Statistical Information and Abbreviations:** The reviewer requests more statistical information and clarification of abbreviations. We acknowledge this. We have added standard deviations for the fine-tuning results on the CC-FT dataset in Table 14. We will also include more statistical information, such as confidence intervals, where appropriate, in the revision. We will also clarify the abbreviations in Tables 1 and 3 and throughout the paper.\n\n*   **Scene Graph Definition:** The reviewer requests a formal definition of \"scene graph.\" We acknowledge this omission. We will add a formal definition of \"scene graph\" in the Introduction (Section 1) and the Overview (Section 3.1), clarifying how it is derived from text. We will also include examples.\n\n*   **Notation Section:** The reviewer points out the lack of a clear notation section. We acknowledge this. We will create a notation table in the appendix or within the methods section (Section 3) to define all symbols and variables used in equations and algorithms.\n\n*   **Bias and Societal Impact:** The reviewer raises concerns about potential biases and societal impacts. We acknowledge this and will add a section in the limitations to address potential biases in the training data and discuss potential negative societal impacts, misuse cases, and mitigation strategies.\n\n*   **Comparison with CREPE and Feature Distortion:** The reviewer requests a more direct comparison with CREPE and clarification of feature distortion issues. We respectfully disagree that this is missing. We already compare with CREPE in Section 4.1 and Table 1. We will clarify the architectural differences and address feature distortion issues in the revision.\n\n**Suggestions:**\n\n*   **Quantitative Comparison with Scene Graph-based VLM:** We will include a quantitative comparison with a state-of-the-art scene graph-based VLM in Section 4.1, as suggested.\n\n*   **Random Seeds and Variance:** We have already addressed this in the \"Weaknesses\" section.\n\n*   **Code Repository and Software Environment:** We have already addressed this in the \"Weaknesses\" section.\n\n*   **Figure Clarity:** We have already addressed this in the \"Weaknesses\" section.\n\n*   **Dataset Details:** We will provide a detailed description of the datasets, including their sources, licenses, and any relevant usage restrictions, and address consent and privacy considerations, and detail the usage terms for the datasets in Appendix E.\n\n*   **Scene Graph Definition:** We have already addressed this in the \"Weaknesses\" section.\n\n*   **Notation Table:** We have already addressed this in the \"Weaknesses\" section.\n\n*   **Ablation Study:** We will conduct an ablation study to isolate the impact of the graph decomposition and augmentation framework and compare the proposed negative mining techniques with the hard negative mining strategies used in [2] and [3] in the next version of the paper."
}