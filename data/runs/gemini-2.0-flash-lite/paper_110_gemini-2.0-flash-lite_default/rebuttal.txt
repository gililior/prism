[
  {
    "rebuttal": "We thank the reviewer for their detailed and insightful feedback. We appreciate the opportunity to clarify our work and address the concerns raised.\n\n**Weaknesses:**\n\n*   **Dataset Licensing and Usage Restrictions:** The reviewer points out the lack of dataset licensing information. We acknowledge this omission and will add explicit license and consent statements for all datasets used (LJ Speech, LibriSpeech, and Libri-light 6k clean) in the next version of the paper. This information will be included in Section 4.1, Datasets and settings.\n\n*   **Clarity of Baseline Models:** The reviewer states that the paper lacks a clear explanation of the baseline models. We believe this is partially addressed. Section 2, Related Work, provides an overview of GSLM (Lakhotia et al., 2021) and other relevant works. Section 4.2, Generation metrics, describes the metrics used for comparison. We will enhance this by explicitly stating the specific configurations of GSLM used for comparison in Section 4, and in the caption of Table 1, Table 3 and Table 10.\n\n*   **Lexical Embedder Definition:** The reviewer requests a clearer definition of the Lexical Embedder. We believe the paper provides a detailed explanation, but we will improve clarity. The Lexical Embedder's function is described in the Abstract, Introduction, and Section 3.1.2. We will expand the explanation in Section 3.1.2 to explicitly state the input (acoustic tokens), output (lexical tokens), and internal workings (PCA and d-k-means). We will also add a more detailed architectural description in Appendix A.3.\n\n*   **Figure 3 Axis Labels:** The reviewer notes the lack of axis labels in Figure 3. We acknowledge this and will add clear labels and units (PPX, VERT) to the axes and include a legend in the next version of the paper.\n\n*   **Statistical Information in Tables:** The reviewer points out the lack of statistical information. We acknowledge this and will include standard deviations or confidence intervals for all reported scores in Tables 1, 3, 4, 5, 6, 7, 8, 9, 10, and 11. We will also add p-values where appropriate to indicate statistical significance. We will also clearly define all acronyms and metrics in the table headers or captions.\n\n*   **Societal Impact Section:** The reviewer requests a dedicated section on societal impact. We agree that this is an important consideration. We will add a Broader Impact section in the next version of the paper (Section 8) that discusses potential risks, such as the generation of deepfakes or the spread of misinformation, and mitigation strategies, as well as the ethical considerations of our work.\n\n**Suggestions:**\n\n*   **Explicit License and Consent Statements:** Addressed above.\n\n*   **Direct Comparison with Discrete Unit-Based GSLMs:** We believe we already provide a direct comparison with GSLM (Lakhotia et al., 2021) in Section 5.1.1 and Table 1. We will clarify the specific configurations used and ensure that the same datasets and evaluation metrics are used for a fair comparison. We will also add a comparison with AudioLM (Borsos et al., 2022) in the next version of the paper.\n\n*   **Detailed Explanation of the Lexical Embedder:** Addressed above.\n\n*   **Figure 3 Enhancements:** Addressed above.\n\n*   **Statistical Information in Tables:** Addressed above.\n\n*   **Broader Impact Section:** Addressed above.\n\n*   **Experiment with Acoustic Word Embeddings:** We respectfully disagree with this suggestion. We have already compared our method with the acoustic word embeddings from Algayres et al. (2022a) in Section A.2.3 and Table 7. We believe that this experiment is sufficient to demonstrate the effectiveness of our approach. We will clarify this in the text.\n\n*   **Ablation Study:** We believe that the ablation study is already present in Section A.2.2 and Table 6. We will clarify the impact of the Lexical Embedding function, contrastive loss, and k-NN sampling in the text."
  }
]