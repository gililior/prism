[
  {
    "rebuttal": "We thank the reviewer for their thorough and insightful feedback. We appreciate the time taken to review our paper and provide constructive criticism. We address each point below:\n\n**Weaknesses:**\n\n*   **Lack of reproducibility (software environment, seeds):** The reviewer is correct that we did not explicitly state the software environment and random seeds. We acknowledge this is a limitation and will address it in the next version. We will include a `requirements.txt` file specifying all dependencies and versions. We will also document the random seeds used for dataset selection, label remapping, and other random processes in Appendix E.4. The reviewer is correct that we did not explicitly state the software environment and random seeds. We acknowledge this is a limitation and will address it in the next version.\n*   **Lack of evidence for algorithmic reasoning and flipped labels claims:** We respectfully disagree. Section 5 and Figure 5 provide detailed results on algorithmic reasoning tasks, showing significant performance improvements. Section 6 and Figure 6 present results on flipped labels, demonstrating that symbol tuning restores the ability to follow flipped labels. We believe the reviewer may have overlooked these sections.\n*   **Comparison to other fine-tuning/prompt engineering:** The reviewer is correct that we did not include a direct comparison with other fine-tuning methods or prompt engineering techniques. We will add a new section in the related work to compare our method with other fine-tuning methods and prompt engineering techniques. We will also include a more in-depth analysis of the specific algorithmic reasoning tasks where symbol tuning shows the most significant improvements.\n*   **Insufficient details on evaluation metrics and statistical significance:** We acknowledge the need for more detail. Section 3.2 describes the evaluation setup, and Appendix F.2 provides per-task results. We will add a more detailed description of the evaluation metrics used, including their definitions and how they are calculated. We will also report the variance of the results by running the experiments with different seeds and include standard deviations or confidence intervals for all reported results to assess statistical significance.\n*   **Lack of axis labels, units, and details in figures/tables:** We acknowledge this oversight. We will add clear labels to the axes of all plots (Figures 1, 2, 3, 5, and 6). Table 1 will be updated to include standard deviations or confidence intervals to show the variability of the results.\n*   **Precision of 'symbol tuning' definition:** We believe the definition in the Abstract and Section 1 is clear. We will add a more detailed explanation of the symbol generation process and include a table summarizing the datasets used for symbol tuning, including their sizes and characteristics in Section 2.\n*   **Lack of methodology section, dataset licensing, fairness, and broader impact:** We acknowledge the need for a dedicated methodology section. We will add a new section to address dataset licensing, fairness considerations, and broader impact. We will also include explicit license and consent statements for datasets used.\n\n**Suggestions:**\n\n*   **Provide code and environment details:** We will provide the code used for prompt generation and evaluation, including the random seed used for example selection and label remapping, and a `requirements.txt` or a Dockerfile to specify the software environment, as mentioned above.\n*   **Report variance and statistical significance:** We will report the variance of the results by running the experiments with different seeds and include standard deviations or confidence intervals for all reported results to assess statistical significance, as mentioned above.\n*   **Direct comparison with other methods:** We will include a direct comparison with other fine-tuning methods or prompt engineering techniques to highlight the advantages of symbol tuning, as mentioned above.\n*   **Detailed evaluation metrics and table details:** We will provide a more detailed description of the evaluation metrics used, including their definitions and how they are calculated, and add clear labels to the axes of all plots. Table 1 will include standard deviations or confidence intervals to show the variability of the results, as mentioned above.\n*   **Detailed symbol generation process:** We will provide a more detailed explanation of the symbol generation process and include a table summarizing the datasets used for symbol tuning, including their sizes and characteristics, as mentioned above.\n*   **License and Broader Impact:** We will add explicit license and consent statements for datasets used and a Broader Impact section with mitigation strategies, as mentioned above.\n\nWe believe these revisions will significantly improve the clarity and rigor of our paper. We are grateful for the reviewer's feedback and are committed to addressing these points in the next version."
  }
]