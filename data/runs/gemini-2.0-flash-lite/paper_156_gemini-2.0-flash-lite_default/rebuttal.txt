[
  {
    "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the time taken to thoroughly review our work and provide constructive criticism. We address each point below:\n\n**Weaknesses:**\n\n*   **Reproducibility and Computational Resources:** The reviewer notes the lack of explicit mention of seeds and computational resources. We acknowledge this omission. While we did not explicitly state the random seeds used, we will include this information in the revised manuscript. We will also add a section detailing the computational resources (e.g., GPU type, memory) used for training and evaluation. We will provide the code, data, and environment details (e.g., Dockerfile, Conda environment) to ensure reproducibility, and specify the random seeds used for all experiments and report the variance of the results across multiple runs.\n\n*   **Overclaiming and Insufficient Analysis:** The reviewer suggests overclaiming and a lack of detailed analysis. We respectfully disagree. We believe that our analysis is sufficient, but we will add more examples and analysis to support the claim that the detectors are complementary. We will also provide more examples and analysis to explain why certain methods perform better in specific resource settings. (Sec 4.2, Figure 8)\n\n*   **Comparison with State-of-the-Art and Annotation Details:** The reviewer requests a comparison with the most recent state-of-the-art methods and more details on annotation. We partially address this. We do compare with several recent methods, as detailed in Section 4.1 and Figure 4. However, we will include a head-to-head comparison with a recent, relevant method for hallucination and omission detection to demonstrate the improvements offered by the new dataset and baselines. We will also provide more details on the annotation process, including the annotation guidelines, inter-annotator agreement, and the qualifications of the annotators. (Intro, Sec 1)\n\n*   **Definitions of 'Internal/External Methods' and 'Resource Levels':** The reviewer points out the lack of clear definitions. We will add explicit definitions of 'internal methods' and 'external methods' when they are first introduced in Section 4.1. We will also provide a table summarizing the language pairs, their resource levels, and scripts in Section 2.1. (Introduction ยง1, Sec 2.1)\n\n*   **Broader Impacts and Ethical Considerations:** The reviewer correctly points out the lack of a dedicated section. We will add an explicit license and consent statements for datasets used and add a Broader Impact section to discuss potential misuse cases, fairness considerations, and the impact on different language communities. (Insufficient evidence)\n\n*   **Data Presentation and Statistical Rigor:** The reviewer highlights the need for improved data presentation. We will include tables with clear headers, concise descriptions of the methods, and complete statistical information (mean, standard deviation, confidence intervals, and p-values). We will add clear labels to the axes, including units where applicable. We will include a comprehensive legend to identify the different methods and their corresponding colors/markers. Consider using error bars to show confidence intervals in the performance plots. (Figures 5, 6, 7, and 8)\n\n**Suggestions:**\n\n*   **Reproducibility:** We will provide the code, data, and environment details (e.g., Dockerfile, Conda environment) to ensure reproducibility, and specify the random seeds used for all experiments and report the variance of the results across multiple runs. (All sections)\n\n*   **Detailed Analysis:** We will conduct more detailed analysis to explain why certain methods perform better in specific resource settings and provide more examples and analysis to support the claim that the detectors are complementary. (Sec 4.2, Figure 8)\n\n*   **Head-to-Head Comparison:** We will include a head-to-head comparison with a recent, relevant method for hallucination and omission detection to demonstrate the improvements offered by the new dataset and baselines. (Related Work, Sec 6)\n\n*   **Annotation Details:** We will provide more details on the annotation process, including the annotation guidelines, inter-annotator agreement, and the qualifications of the annotators. (Intro, Sec 1)\n\n*   **Broader Impact:** We will add explicit license and consent statements for datasets used and add a Broader Impact section to discuss potential misuse cases, fairness considerations, and the impact on different language communities. (Insufficient evidence)\n\n*   **Data Presentation:** We will include tables with clear headers, concise descriptions of the methods, and complete statistical information (mean, standard deviation, confidence intervals, and p-values). We will add clear labels to the axes, including units where applicable. We will include a comprehensive legend to identify the different methods and their corresponding colors/markers. Consider using error bars to show confidence intervals in the performance plots. (Figures 5, 6, 7, and 8)\n\n*   **Definitions:** We will define 'internal methods' and 'external methods' when they are first introduced and provide a table summarizing the language pairs, their resource levels, and scripts in Section 2.1. (Introduction ยง1, Sec 2.1)\n\n*   **COMET Comparison:** We will conduct an experiment comparing the proposed method with COMET on the new dataset, evaluating the performance using metrics like precision, recall, and F1-score for both hallucination and omission detection. (Sec 6)\n\nWe believe that these revisions will significantly improve the clarity, rigor, and impact of our work. Thank you again for your valuable feedback."
  }
]