{
  "rebuttal": "We sincerely thank the reviewer for their detailed and insightful feedback. We appreciate the time and effort taken to thoroughly review our paper. We address each point below:\n\n**Weaknesses:**\n\n*   **Statistical Information:** The reviewer requests standard deviations, confidence intervals, and p-values. We acknowledge this is a valid point. While we present F1 scores, we did not include these statistical measures. We will include standard deviations (calculated over the 10 random seeds used for few-shot experiments) and p-values (using a t-test to compare our model with the best baselines) in Tables 2, 3, 4, and 5 of the revised manuscript. We will also add confidence intervals where appropriate.\n\n*   **Pruning Strategy:** The reviewer requests more details on the pruning strategy. We believe this is partially addressed in Section 3.2.1, which describes the removal of first-order neighbors with a degree of one. We will clarify this further by explicitly stating the rationale: pruning reduces noise and focuses on the most relevant relationships for each entity pair. We will also add a sentence to Section 3.2.1 explaining that this strategy was chosen to balance knowledge preservation with computational efficiency.\n\n*   **Comparison with Prior Work:** We respectfully disagree. Section 2.2 already discusses and compares our work with relevant prior work, including Dun et al. (2021) and Jiang et al. (2022). We will strengthen this comparison by adding a table summarizing the key differences between our approach and these baselines, specifically highlighting how we incorporate both coarse- and fine-grained knowledge representations, which is a novel contribution.\n\n*   **Few-Shot Overclaiming:** The reviewer is correct that our model's performance in the few-shot setting is not always superior. We will revise Section 4.4 and Table 2 to more accurately reflect this, emphasizing that our model is competitive in the few-shot setting, and highlight the cases where it outperforms the baselines. We will also add a sentence acknowledging the instability of the results in this setting due to the limited training data.\n\n*   **Figure Clarity:** We acknowledge the need for improved figure clarity. We will add axis labels and legends to Figures 1 and 3. We will also consider adding error bars to the performance plots in the revised manuscript.\n\n*   **Dataset Information, Consent, Bias, Ethical Considerations, Malicious Use, Societal Impact:** We acknowledge the importance of these points. We will add a new section to the paper titled \"Ethical Considerations\" to address these concerns. This section will include details on the datasets used (sources, licenses, and any usage restrictions), a discussion of potential biases in the datasets and model, and proposed mitigation strategies. We will also discuss the potential for malicious use and broader societal impacts.\n\n*   **'Entity Graph' Definition:** The term 'entity graph' is introduced in the Abstract and Introduction. We will add a precise definition of 'entity graph' in Section 3.2.1, clarifying that it consists of entities extracted from the news content and their first-order neighbors in the knowledge graph.\n\n*   **GNN Architecture:** The reviewer requests clarification on the GNN architecture. We will specify the GAT architecture used in Section 3.2.2, including the number of layers, hidden units, and activation functions.\n\n*   **Biases in Knowledge Graphs:** We will add a discussion of potential biases in the knowledge graphs and datasets used, and how we plan to mitigate these biases in the \"Ethical Considerations\" section.\n\n*   **Seeds and Variance:** We will include the random seeds used for all experiments and report the standard deviation across multiple runs in Section 4.4, as suggested.\n\n*   **Code/Data Availability:** We will provide a link to the code repository and the datasets used, or state the reason for their unavailability in the revised manuscript.\n\n**Suggestions:**\n\n*   **Random Seeds and Variance:** Addressed above.\n\n*   **Code/Data Availability:** Addressed above.\n\n*   **Software/Hardware Environment:** We will add a section in the Appendix detailing the software environment (e.g., Python version, library versions) and hardware used for the experiments.\n\n*   **Head-to-Head Comparison:** Addressed above.\n\n*   **Ablation Studies:** We believe we already provide ablation studies in Section 4.5 and Table 5 to demonstrate the contribution of both coarse- and fine-grained knowledge representations. We will clarify this in the revised manuscript.\n\n*   **Few-Shot Analysis:** Addressed above.\n\n*   **Figure Improvements:** Addressed above.\n\n*   **Statistical Significance:** Addressed above.\n\n*   **Dataset Information, Consent, Bias, Ethical Considerations, Malicious Use, Societal Impact:** Addressed above.\n\n*   **'Entity Graph' Definition:** Addressed above.\n\n*   **GNN Architecture:** Addressed above.\n\n*   **Notation Table:** We will add a notation table to define all symbols used in the equations and throughout the paper.\n\n*   **Bias Mitigation:** Addressed above.\n\n*   **Malicious Use and Societal Impact:** Addressed above.\n\nWe believe these revisions will significantly improve the clarity, rigor, and impact of our paper. Thank you again for the valuable feedback."
}