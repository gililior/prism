{
  "rebuttal": "We thank the reviewer for their detailed and insightful feedback. We appreciate the opportunity to clarify our work and address the concerns raised.\n\n**Weaknesses:**\n\n*   **Lack of experimental setup details (datasets, metrics, baselines, seeds, variance, environment):** We acknowledge that the initial submission lacked sufficient detail in the experimental setup. While we provided dataset descriptions and evaluation metrics in Section 4 and Appendix D, we agree that more specifics are needed. We will add the following to the next version: (1) Detailed descriptions of all datasets, including sizes, compositions, and preprocessing steps (as suggested). (2) The seeds used for all experiments and report the variance across multiple runs. (3) A requirements file specifying the environment. (4) More details on baseline comparisons, including the exact configurations used.\n\n*   **Overclaiming benefits and insufficient evidence for claims:** We respectfully disagree that we overclaim the benefits. We explicitly state in Section 5 that our method shows improved performance on multiple architectures (CLIP, BLIP, and BLIP2) on a variety of VL datasets with only *mild* degradation in zero-shot performance. We believe the results in Tables 1-3 and the ablation studies in Table 4 and Appendix A.1 provide sufficient evidence. We will strengthen the discussion in Section 5 to emphasize the limitations and the need for further research.\n\n*   **Lack of clear comparison with existing methods:** The reviewer is correct that a direct comparison with BLIP-2 is missing. We will add a head-to-head comparison with BLIP-2, including quantitative results on the same datasets, in the next version. We will also expand the Related Work section to more clearly articulate the delta compared to the closest baselines.\n\n*   **Insufficient details on architecture and hard-negative caption generation:** The reviewer is correct that the initial description of the 'SG Component' and hard-negative caption generation could be improved. We will provide a more detailed explanation of the 'Adaptive Scene Graph Tokens' and their role in the image transformer encoder, including how they are trained and how they interact with other tokens. We will also include a more detailed description of the graph-based negative generation process in Section B.2 and Figure 7.\n\n*   **Lack of a dedicated notation section:** We acknowledge the lack of a dedicated notation section. We will add a notation table to define all symbols and abbreviations used in the paper to improve clarity.\n\n*   **Dataset licenses, consent, and privacy:** We address dataset licenses, PII, and consent details in Section D.6. We will expand this section to explicitly state the licenses and consent statements for datasets used and include a section on ethical considerations, discussing potential biases and privacy implications. We will also clarify the usage terms of the model and datasets and add a Broader Impact section with mitigation strategies.\n\n*   **Vague table descriptions and lack of statistical information:** We will revise the table titles and column headers to be more clear and concise. We will include standard deviations or confidence intervals to quantify the variability of the results. We will also add p-values to indicate the statistical significance of the performance differences between the proposed method and the baselines, and specify the exact experimental setup, including the number of trials or repetitions, to ensure reproducibility.\n\n*   **Figure 4 not described:** The reviewer appears to have overlooked the description of Figure 4. Figure 4 is described in Section 4.4 and its caption explains the different components and results. We will improve the caption to make it more self-contained.\n\n**Suggestions:**\n\n*   **Detailed dataset descriptions, seeds, and variance:** Addressed above.\n*   **Code/Data Availability:** We will provide the code, including training and evaluation scripts, and a requirements file to specify the environment.\n*   **Ablation study:** We already provide an ablation study in Table 4 and Appendix A.1, which isolates the contribution of each component. We will expand this study to include BLIP-2 in the next version.\n*   **Head-to-head comparison:** Addressed above.\n*   **Detailed explanation of 'Adaptive Scene Graph Tokens' and notation table:** Addressed above.\n*   **Figure labeling and caption for Figure 4:** Addressed above.\n*   **License, consent, ethical considerations, and Broader Impact:** Addressed above.\n*   **Clear table titles, column headers, and statistical information:** Addressed above.\n\nWe believe these revisions will significantly improve the clarity and impact of our paper. Thank you again for your valuable feedback."
}